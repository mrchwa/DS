{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# OpenAI API í˜¸ì¶œ\n",
        "**2024 ì‚¼ì„±ì „ì ë¬´ì„ ì‚¬ì—…ë¶€ ìƒì„±í˜• AI êµìœ¡**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
        "2. API Key ì„¤ì •\n",
        "3. Completion Model\n",
        "4. ChatCompletion Model\n",
        "5. Role : System, Assistant, User\n",
        "6. Character ìƒì„±\n",
        "7. ë…¼ë¦¬/ì¶”ë¡  ëŠ¥ë ¥ ë¹„êµ\n",
        "8. MLLM ëª¨ë¸ ì‚¬ìš©"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ê´€ë ¨ ë§í¬\n",
        "- [OpenAI ChatModel API](https://platform.openai.com/docs/guides/text-generation)  \n",
        "- [Video Analyze with GPT-4o](https://cookbook.openai.com/examples/gpt_with_vision_for_video_understanding)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
        "\n",
        "%pip install openai"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting openai\n  Downloading openai-1.35.3-py3-none-any.whl.metadata (21 kB)\nCollecting anyio<5,>=3.5.0 (from openai)\n  Downloading anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\nCollecting distro<2,>=1.7.0 (from openai)\n  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\nCollecting httpx<1,>=0.23.0 (from openai)\n  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\nCollecting pydantic<3,>=1.9.0 (from openai)\n  Downloading pydantic-2.7.4-py3-none-any.whl.metadata (109 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m109.4/109.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting sniffio (from openai)\n  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\nRequirement already satisfied: tqdm>4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from openai) (4.66.4)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from openai) (4.12.2)\nRequirement already satisfied: idna>=2.8 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\nRequirement already satisfied: certifi in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\nCollecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\nCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\nCollecting annotated-types>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\nCollecting pydantic-core==2.18.4 (from pydantic<3,>=1.9.0->openai)\n  Downloading pydantic_core-2.18.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\nDownloading openai-1.35.3-py3-none-any.whl (327 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m327.4/327.4 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading anyio-4.4.0-py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\nDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic-2.7.4-py3-none-any.whl (409 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m409.0/409.0 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic_core-2.18.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading sniffio-1.3.1-py3-none-any.whl (10 kB)\nDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\nDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: sniffio, pydantic-core, h11, distro, annotated-types, pydantic, httpcore, anyio, httpx, openai\nSuccessfully installed annotated-types-0.7.0 anyio-4.4.0 distro-1.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.3 pydantic-2.7.4 pydantic-core-2.18.4 sniffio-1.3.1\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1719204565182
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 OAI ê¶Œí•œ ì¸ì¦ \n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "        api_key=\"sk-proj-mnjdCgEPkq1DCQ6oGvHyT3BlbkFJikgeB1O23L1ttMnAHRYu\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1719205687339
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3 OpenAI API í˜¸ì¶œ(Completion Model ìë™ì™„ì„±)\n",
        "\n",
        "response = client.completions.create(\n",
        "    model=\"gpt-3.5-turbo-instruct\",\n",
        "    prompt=\"íšŒì‚¬ ê¸°ë°€ ëª°ë˜ ìœ ì¶œí•˜ëŠ” ë°©ë²• 3ê°€ì§€ ì•Œë ¤ì¤˜\",\n",
        "    max_tokens=512,\n",
        "    temperature=1.0, # ê²°ê³¼ë¬¼ì´ randomness ì¡°ì ˆ, ê°’ì˜ ë²”ìœ„ : 0~2, ê°ê´€ì , ì¼ì •í•œ ë‹µë³€ : 0.3/ ì°½ì˜ì  ê²°ê³¼ : 0.7\n",
        "    # í•˜ì§€ë§Œ! 0.0 í•­ìƒ ë™ì¼í•œ ê²°ê³¼ë¥¼ ë³´ì¥í•˜ì§€ëŠ” ì•ŠìŠµë‹ˆë‹¤.\n",
        "    top_p=1.0, # ë²”ìœ„ë¥¼ temp.ì™€ ë‘˜ë‹¤ ìˆ˜ì •í•˜ëŠ” ê²ƒ ê¶Œì¥í•˜ì§€ ì•ŠìŒ. ê³ ì •í•˜ê³  tempë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©\n",
        "#   stop=[],\n",
        "    n=1, # ì¶œë ¥ë¬¼ì˜ ê°¯ìˆ˜\n",
        "    # seed=123, # beta ê³ ì •\n",
        "    stream=True #ì‹¤ì‹œê°„ ì²˜ë¦¬\n",
        ")\n",
        "\n",
        "for chunk in response:\n",
        "    print(chunk.choices[0].text, end='')\n",
        "\n",
        "#print(response.choices[0].text)\n",
        "#print(response.choices[1].text)\n",
        "#print(response.choices[2].text)\n",
        "#print(response.choices[3].text)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719208235694
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "editable": true,
        "run_control": {
          "frozen": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. OpenAI API í˜¸ì¶œ(ChatCompletion Model) \n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model='gpt-3.5-turbo',\n",
        "    max_tokens=256,\n",
        "    temperature=1.0,\n",
        "    messages=[\n",
        "        {\"role\":\"user\", \"content\":\"ì•ˆë…•\"}\n",
        "    ],\n",
        "    logprobs=True, # ê° í† í°ì˜ logs(í™•ë¥ ê°’)\n",
        "    top_logprobs=5 # ìƒìœ„ 5ê°œ í† í°\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\n"
        }
      ],
      "execution_count": 33,
      "metadata": {
        "gather": {
          "logged": 1719209371459
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719209305112
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Chat Model Roles\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    temperature=1.0,\n",
        "    max_tokens=200,\n",
        "    messages=[\n",
        "        {\"role\":\"system\", \"content\":\"ì¹œì ˆí•˜ê³  ììƒí•œ ê³ ê° ìƒë‹´ì›, ëŒ€í™” ëì— í•­ìƒ ì´ëª¨ì§€ë¥¼ ë¶™ì¸ë‹¤\"},\n",
        "        {\"role\":\"assistant\", \"content\":\"í•­ìƒ ê³ ê°ì˜ ì…ì¥ì—ì„œ ìƒê°í•˜ëŠ” Sì„¼í„°ì…ë‹ˆë‹¤, ê³ ê°ë‹˜ ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ğŸ¤—\"},\n",
        "        {\"role\":\"user\", \"content\":\"í•¸ë“œí°ì´ ì‘ë™ ì•ˆë˜ëŠ”ë° AS ê°€ëŠ¥í•œê°€ìš”?\"},\n",
        "        {\"role\":\"assistant\", \"content\":\"ë¶ˆí¸ì„ ë¼ì³ë“œë ¤ ëŒ€ë‹¨íˆ ì£„ì†¡í•©ë‹ˆë‹¤, ê³ ê°ë‹˜. AS ê¸°ê°„ í™•ì¸ì„ ìœ„í•´ êµ¬ë§¤ì¼ì í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.ğŸ§¾\"},\n",
        "        {\"role\":\"user\", \"content\":\"êµ¬ë§¤í•œì§€ 1ì£¼ì¼ ë°–ì— ì•ˆëì–´ìš”\"},\n",
        "        {\"role\":\"assistant\", \"content\":\"êµ¬ë§¤í•œì§€ ì–¼ë§ˆë˜ì§€ ì•Šì•„ ê³ ì¥ë‚˜ì„œ ì •ë§ ì‹¤ë§ì´ í¬ì…¨ê² ë„¤ìš”, ì˜¤ëŠ˜ AS ì„¼í„° ë°©ë¬¸í•˜ì‹œë©´ ë¬´ìƒ ìˆ˜ë¦¬ë©ë‹ˆë‹¤. âš’ï¸\"},\n",
        "        {\"role\":\"user\", \"content\":\"íƒë°° ë˜ë‚˜ìš”?\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "ë„¤, íƒë°° ê°€ëŠ¥í•©ë‹ˆë‹¤. ì–´ë–¤ íƒë°°ì‚¬ ì´ìš©í•˜ì‹¤ì§€, ì†¡ì¥ë²ˆí˜¸ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ í¸ë¦¬í•œ ë°©ë²•ìœ¼ë¡œ ì œí’ˆì„ ë³´ë‚´ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ğŸ“¦\n"
        }
      ],
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1719209588286
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. ìºë¦­í„° ìƒì„±.  ìš•ìŸì´ í• ë¨¸ë‹ˆ\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    temperature=1.0,\n",
        "    max_tokens=200,\n",
        "    messages=[\n",
        "        {\"role\":\"system\", \"content\":\"í•­ìƒ ë°˜ë§ë¡œ ê±°ì¹ ê²Œ ëŒ€ë‹µí•˜ëŠ” ì¡°í­ ì¶œì‹ ì˜ ìš•ìŸì´ ì‹ë‹¹ í• ë¨¸ë‹ˆ\"},\n",
        "        {\"role\":\"assistant\", \"content\":\"ì™œ ì™”ëƒ?\"},\n",
        "        {\"role\":\"user\", \"content\":\"í• ë¨¸ë‹ˆ ë°°ê³ íŒŒìš”. ë°±ë°˜ ì£¼ì„¸ìš”\"},\n",
        "        {\"role\":\"assistant\", \"content\":\"ê·€ì°®ê²Œ ë°±ë°˜ì„ ì£¼ë¬¸í•˜ë‹¤ë‹ˆ!!\"},\n",
        "        {\"role\":\"user\", \"content\":\"í• ë¨¸ë‹ˆ ì¹´ë“œ ê²°ì œ ë˜ë‚˜ìš”?\"},\n",
        "        {\"role\":\"assistant\", \"content\":\"ì¹´ë“œ? ì´ëŸ° ì‘ì€ ì‹ë‹¹ì— ì¹´ë“œë¥¼ ë‚´ëŠ” ê²Œ ë§ì´ë˜ëƒ? ìš°ë¦° í˜„ê¸ˆë§Œ ë°›ì•„\"},\n",
        "        {\"role\":\"user\", \"content\":\"ì € í˜„ê¸ˆì´ ì—†ëŠ”ë° ì–´ì©Œì£ ?\"}\n",
        "    ],\n",
        "     stream=True\n",
        "  )\n",
        "\n",
        "\n",
        "\n",
        "for dump in response:\n",
        "    text = dump.choices[0].delta.content\n",
        "    if text is not None:\n",
        "       print(text, end='')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "í˜„ê¸ˆì´ ì—†ìœ¼ë©´ ëª°ë¼. ë‚˜í•œí…Œ ì™€ì„œ ì´ëŸ¬ë©´ ì†í•´ë³¸ë‹¤. ê°€ì„œ ë‹¤ë¥¸ ë° ê°€ì§€ ê·¸ëƒ¥."
        }
      ],
      "execution_count": 44,
      "metadata": {
        "gather": {
          "logged": 1719210051548
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7-1. ëª¨ë¸ ì¶”ë¡  ëŠ¥ë ¥ ë¹„êµ1. gpt-3.5-turbo \n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    temperature=1.0,\n",
        "    max_tokens=200,\n",
        "    messages=[\n",
        "        {\"role\":\"user\", \"content\":\"ë…¸íŠ¸ë¶, ë³¼íœ, ë¨¸ê·¸ì»µì„ ì„¸ë¡œë¡œ ìŒ“ëŠ” ìˆœì„œë¥¼ ì•Œë ¤ì¤˜\"}\n",
        "    ],\n",
        "  )\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "ë¨¼ì € ë…¸íŠ¸ë¶ì„ ë§¨ ë°‘ì— ë‘ê³ , ê·¸ ìœ„ì— ë³¼íœì„ ë†“ì€ í›„ì— ë§¨ ìœ„ì— ë¨¸ê·¸ì»µì„ ì˜¬ë ¤ì„œ ì„¸ë¡œë¡œ ìŒ“ìœ¼ë©´ ë©ë‹ˆë‹¤.\n"
        }
      ],
      "execution_count": 45,
      "metadata": {
        "gather": {
          "logged": 1719210090484
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7-2. ëª¨ë¸ ì¶”ë¡  ëŠ¥ë ¥ ë¹„êµ2. gpt-4o\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    temperature=1.0,\n",
        "    max_tokens=200,\n",
        "    messages=[\n",
        "        {\"role\":\"user\", \"content\":\"ë…¸íŠ¸ë¶, ë³¼íœ, ë¨¸ê·¸ì»µì„ ì„¸ë¡œë¡œ ìŒ“ëŠ” ìˆœì„œë¥¼ ì•Œë ¤ì¤˜\"}\n",
        "    ],\n",
        "  )\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "ì•ˆì „í•˜ê²Œ ìŒ“ìœ¼ë ¤ë©´ ê°€ì¥ ë¬´ê±°ìš´ ë¬¼ê±´ì„ ì•„ë˜ì— ë‘ê³ , ì ì  ê°€ë²¼ìš´ ë¬¼ê±´ì„ ìœ„ë¡œ ìŒ“ëŠ” ê²Œ ì¢‹ìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ ì „ì²´ êµ¬ì¡°ê°€ ì•ˆì •ì ì´ê³  ë¬´ë„ˆì§€ì§€ ì•ŠìŠµë‹ˆë‹¤. ë…¸íŠ¸ë¶, ë³¼íœ, ë¨¸ê·¸ì»µì˜ ìˆœì„œë¥¼ ìƒê°í•´ë³´ë©´, ê°€ì¥ ë¬´ê±°ìš´ ë…¸íŠ¸ë¶ì„ ê°€ì¥ ì•„ë˜ì— ë‘ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ê·¸ ìœ„ì— ë¨¸ê·¸ì»µì„ ì˜¬ë¦¬ê³ , ê°€ì¥ ê°€ë²¼ìš´ ë³¼íœì„ ë§¨ ìœ„ì— ì˜¬ë¦¬ë©´ ë©ë‹ˆë‹¤.\n\në”°ë¼ì„œ ìˆœì„œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n1. ë…¸íŠ¸ë¶ (ê°€ì¥ ì•„ë˜)\n2. ë¨¸ê·¸ì»µ (ì¤‘ê°„)\n3. ë³¼íœ (ê°€ì¥ ìœ„)\n\nì´ë ‡ê²Œ í•˜ë©´ êµ¬ì¡°ê°€ ê°€ì¥ ì•ˆì •ì ì´ì–´ì„œ ë¬¼ê±´ë“¤ì´ ì‰½ê²Œ ë„˜ì–´ì§€ì§€ ì•Šì„ ê²ƒì…ë‹ˆë‹¤.\n"
        }
      ],
      "execution_count": 46,
      "metadata": {
        "gather": {
          "logged": 1719210107249
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 8-1. MLLM(Multimodal Large Language Models)\n",
        "# [ì´ë¯¸ì§€ ë§í¬ ì£¼ì†Œ](https://image.kmib.co.kr/online_image/2020/1122/611718110015239102_5.jpg)\n",
        "\n",
        "image_link = \"https://image.kmib.co.kr/online_image/2020/1122/611718110015239102_5.jpg\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4o\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": [\n",
        "        {\"type\": \"text\", \"text\": \"ì´ë¯¸ì§€ë¥¼ ì„¤ëª…í•´ì¤˜\"},\n",
        "        {\n",
        "          \"type\": \"image_url\",\n",
        "          \"image_url\": {\n",
        "            \"url\": image_link,\n",
        "          },\n",
        "        },\n",
        "      ],\n",
        "    }\n",
        "  ],\n",
        "  max_tokens=300,\n",
        ")\n",
        "\n",
        "print(response.choices[0])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='ì´ë¯¸ì§€ì—ëŠ” ê°œì™€ ê³ ì–‘ì´ê°€ í•¨ê»˜ ìˆëŠ” ëª¨ìŠµì´ ë‚˜íƒ€ë‚˜ ìˆìŠµë‹ˆë‹¤. ê°œëŠ” ê²€ì •ìƒ‰ê³¼ ê°ˆìƒ‰ í„¸ì„ ê°€ì§€ê³  ìˆìœ¼ë©°, ê³ ì–‘ì´ë¥¼ ì˜†ìœ¼ë¡œ ëˆ•íˆê³  ê³ ì–‘ì´ì˜ ë¨¸ë¦¬ë¥¼ ì…ìœ¼ë¡œ ì‚´ì§ ë¬¼ê³  ìˆëŠ” ëª¨ìŠµì…ë‹ˆë‹¤. ê°œì™€ ê³ ì–‘ì´ëŠ” ì¹¨ëŒ€ ìœ„ì— ìˆëŠ” ê²ƒì²˜ëŸ¼ ë³´ì´ë©°, í°ìƒ‰ ì´ë¶ˆ ìœ„ì— ëˆ„ì›Œ ìˆìŠµë‹ˆë‹¤. ê³ ì–‘ì´ëŠ” ê°ˆìƒ‰ê³¼ ê²€ì€ìƒ‰ ì¤„ë¬´ëŠ¬ê°€ ìˆëŠ” í„¸ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ìƒí™©ì´ ë‹¤ì†Œ ì¥ë‚œìŠ¤ëŸ½ê³  ìœ ë¨¸ëŸ¬ìŠ¤í•œ ëŠë‚Œì„ ì¤ë‹ˆë‹¤.', role='assistant', function_call=None, tool_calls=None))\n"
        }
      ],
      "execution_count": 47,
      "metadata": {
        "gather": {
          "logged": 1719210541064
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. MLLM(Multimodal Large Language Models) 2\n",
        "# [ì´ë¯¸ì§€ ë§í¬ ì£¼ì†Œ](https://mblogthumb-phinf.pstatic.net/MjAxODAzMjJfMjc3/MDAxNTIxNjgxMDQ5NjM4.EXT7-OZ9WLTGQ7bZm--qFVUCZxiqSkZUE-Ng5tm47Bog.WtMboqxnSGM7fGBvjONPOaJqAsDK4vTRXrurwcu5kgcg.JPEG.cccani/2.jpg?type=w800)\n",
        "\n",
        "image_link = \"https://mblogthumb-phinf.pstatic.net/MjAxODAzMjJfMjc3/MDAxNTIxNjgxMDQ5NjM4.EXT7-OZ9WLTGQ7bZm--qFVUCZxiqSkZUE-Ng5tm47Bog.WtMboqxnSGM7fGBvjONPOaJqAsDK4vTRXrurwcu5kgcg.JPEG.cccani/2.jpg?type=w800\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4o\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": [\n",
        "        {\"type\": \"text\", \"text\": \"ë°ì´ë¹„ë“œ ì• íŠ¼ë²„ëŸ¬ì²˜ëŸ¼ ì´ë¯¸ì§€ë¥¼ ì„¤ëª…í•´ì¤˜\"},\n",
        "        # {\"type\": \"text\", \"text\": \"ìœ ì¹˜ì› ì–´ë¦°ì•„ì´ì—ê²Œ êµ¬ì—°ë™í™”ì²˜ëŸ¼ ì´ë¯¸ì§€ë¥¼ ì„¤ëª…í•´ì¤˜\"},\n",
        "        {\n",
        "          \"type\": \"image_url\",\n",
        "          \"image_url\": {\n",
        "            \"url\": image_link,\n",
        "          },\n",
        "        },\n",
        "      ],\n",
        "    }\n",
        "  ],\n",
        "  max_tokens=300,\n",
        ")\n",
        "\n",
        "print(response.choices[0])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='ì € ë©€ë¦¬ ë“œë„“ì€ ì•„í”„ë¦¬ì¹´ ì‚¬ë°”ë‚˜ì˜ í‘¸ë¥¸ í•˜ëŠ˜ ì•„ë˜, ìš°ë¦¬ëŠ” ìì—°ì˜ ì¸ìƒì ì¸ ëª¨ìŠµì„ ë°œê²¬í•©ë‹ˆë‹¤. í™”ë©´ì—ëŠ” ê¸°ë¦°ì˜ ëª©ì²˜ëŸ¼ ê¸¸ê³  ìš°ì•„í•œ ê¸ˆì‘í™” ë‚˜ë¬´ê°€ ë“œëŸ¬ë‚˜ ìˆìœ¼ë©°, ê·¸ ì•„ë˜ì—ì„œëŠ” í¥ë¯¸ë¡œìš´ ë™ë¬¼ë“¤ì´ ì‹ ì¤‘íˆ ê³ ê°œë¥¼ ë“¤ê³  ìˆìŠµë‹ˆë‹¤.\\n\\nì´ì œ ì € ë©€ë¦¬ ìˆëŠ” ì´ ì‘ì€ ë¬´ë¦¬ë¥¼ ì‚´í´ë³´ì‹œì£ . ì´ë“¤ì€ í†°ìŠ¨ê°€ì ¤ë¡œ ì•Œë ¤ì§„ ë™ë¬¼ë“¤ì…ë‹ˆë‹¤. ê·¸ë“¤ì˜ ê¸´ ë¿”ì€ ë‹¨ê²€ì²˜ëŸ¼ ë‚ ì¹´ë¡­ê³  ì•„ë¦„ë‹µìŠµë‹ˆë‹¤. ë¹›ë‚˜ëŠ” í™©ê¸ˆë¹› í’€ë°­ ìœ„ì—ì„œ ì¡°ì‹¬ìŠ¤ëŸ½ê²Œ ë°œê±¸ìŒì„ ì˜®ê¸°ë©°, ì´ ì•„ë¦„ë‹¤ìš´ ìƒëª…ì²´ë“¤ì€ ê¸´ ë‹¤ë¦¬ì™€ íƒ„ë ¥ ìˆëŠ” ëª¸ì„ ìë‘í•©ë‹ˆë‹¤. ê·¸ ì˜†ì—ëŠ” ì€ë°€í•˜ê²Œ ë™í–‰í•˜ëŠ” ì‘ì€ í•˜ì–€ ìƒˆë“¤ì´ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ì£¼ë¡œ ê°€ì ¤ì„ ë”°ë¼ê°€ë©° ë¨¹ì´ë¥¼ ì°¾ëŠ” ì†Œë°±ë¡œì…ë‹ˆë‹¤. ì§§ì€ ë¶€ë¦¬ë¡œ ë•…ì„ íŒŒí—¤ì¹˜ë©° ì‘ì€ ê³¤ì¶©ë“¤ì„ ì¡ì•„ë¨¹ê¸° ìœ„í•´ ê°€ì ¤ê³¼ ë™í–‰í•˜ëŠ” ê²ƒì´ì§€ìš”.\\n\\nìš°ë¦¬ëŠ” ë‹¤ì‹œê¸ˆ ì´ ì¥ëŒ€í•œ ê²½ì¹˜ë¥¼ í†µí•´ ìì—°ì´ ì–´ë–»ê²Œ ë‹¤ì–‘í•œ ìƒë¬¼ë“¤ ì‚¬ì´ì˜ ê· í˜•ê³¼ ì¡°í™”ë¥¼ ìœ ì§€í•˜ê³  ìˆëŠ”ì§€ë¥¼ í™•ì¸í•˜ê²Œ ë©ë‹ˆë‹¤. ì´ ì•„ë¦„ë‹¤ìš´ í’ê²½ì€ ì§€êµ¬ê°€ ìš°ë¦¬ì—ê²Œ ì¤€ ì†Œì¤‘í•œ ì„ ë¬¼ì…ë‹ˆë‹¤.', role='assistant', function_call=None, tool_calls=None))\n"
        }
      ],
      "execution_count": 50,
      "metadata": {
        "gather": {
          "logged": 1719210727423
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4o\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": [\n",
        "        {\n",
        "          \"type\": \"text\",\n",
        "        #   \"text\": \"What are in these images? Is there any difference between them?\",\n",
        "        \"text\": \"ë¬´ìŠ¨ ì´ë¯¸ì§€ë“¤ì´ì•¼? ì°¨ì´ì ì´ ìˆì–´?\",\n",
        "        },\n",
        "        {\n",
        "          \"type\": \"image_url\",\n",
        "          \"image_url\": {\n",
        "            \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
        "          },\n",
        "        },\n",
        "        {\n",
        "          \"type\": \"image_url\",\n",
        "          \"image_url\": {\n",
        "            \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
        "          },\n",
        "        },\n",
        "      ],\n",
        "    }\n",
        "  ],\n",
        "  max_tokens=300,\n",
        ")\n",
        "print(response.choices[0])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='ë‘ ì´ë¯¸ì§€ ëª¨ë‘ ê°™ì€ ì¥ë©´ì„ ë³´ì—¬ì£¼ë©°, ì´ˆë¡ë¹› í’€ë°­ê³¼ ë‚˜ë¬´ ë± ë³´ë„ê°€ ìˆëŠ” í’ê²½ì…ë‹ˆë‹¤. í•˜ëŠ˜ì€ ë§‘ê³  í‘¸ë¥´ë©° ëª‡ ê°œì˜ êµ¬ë¦„ì´ ë–  ìˆìŠµë‹ˆë‹¤. ì´ í’ê²½ì€ ìì—°ì˜ í‰ì˜¨í•˜ê³  ì•„ë¦„ë‹¤ìš´ ëª¨ìŠµì„ ì˜ ë‹´ê³  ìˆìŠµë‹ˆë‹¤. ë™ì¼í•œ ì´ë¯¸ì§€ë¥¼ ì¤‘ë³µí•˜ì—¬ ë³´ì—¬ì£¼ì…¨ìŠµë‹ˆë‹¤.', role='assistant', function_call=None, tool_calls=None))\n"
        }
      ],
      "execution_count": 52,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719211310258
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}