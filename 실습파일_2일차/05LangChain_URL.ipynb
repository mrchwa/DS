{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "w2GM8vtc_FBB",
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# LangChain + Web Data\n",
        "**2024 삼성전자 무선사업부 생성형 AI 교육**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dzXcYq79_FBE",
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "1. 기본 패키지 설정\n",
        "2. 소스 링크 수집\n",
        "3. 데이터 불러오기\n",
        "4. 데이터 Split\n",
        "5. 데이터 Embedding\n",
        "6. LLM 생성\n",
        "7. Chain 연결"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1716275184413
        },
        "id": "QxUxWYS4xd91",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# 1. 패키지 설치\n",
        "\n",
        "%pip install chromadb\n",
        "%pip install unstructured"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1716702521049
        },
        "id": "Ua4tsQUd_FBG",
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# 2. 기본 패키지 설정 & AzureOpenAI 환경설정\n",
        "\n",
        "# 환경 변수 설정!! \n",
        "import os\n",
        "import langchain\n",
        "\n",
        "from config_azure import (\n",
        "    AZURE_OPENAI_API_VERSION,\n",
        "    AZURE_OPENAI_ENDPOINT,\n",
        "    AZURE_OPENAI_KEY\n",
        ")\n",
        "# lagchain 사용시 반드시 환경변수 값 사용!!\n",
        "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = AZURE_OPENAI_KEY\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = AZURE_OPENAI_ENDPOINT\n",
        "os.environ[\"OPENAI_API_VERSION\"] = AZURE_OPENAI_API_VERSION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1716702521108
        },
        "id": "VMWlGkXF_FBH",
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# 3. 소스 링크 수집\n",
        "# [링크 바로가기](https://www.xn--hq1bn9iz0nvzar4a.net/%ec%95%a0%ec%9b%94-%ed%98%91%ec%9e%ac-%eb%a7%9b%ec%a7%91-best-10/\")\n",
        "\n",
        "urls = [\n",
        "    \"https://www.xn--hq1bn9iz0nvzar4a.net/%ec%95%a0%ec%9b%94-%ed%98%91%ec%9e%ac-%eb%a7%9b%ec%a7%91-best-10/\",\n",
        "    \"https://www.xn--hq1bn9iz0nvzar4a.net/%ec%95%a0%ec%9b%94-%eb%a7%9b%ec%a7%91-best-10/\",\n",
        "    \"https://m.blog.naver.com/miya75kr/223390881363\",\n",
        "    \"https://m.blog.naver.com/kongmistar/223444031844\",\n",
        "    \"https://m.blog.naver.com/psmr1234/223188197427\",\n",
        "    \"https://www.xn--hq1bn9iz0nvzar4a.net/%ec%a0%9c%ec%a3%bc-%ea%b3%b5%ed%95%ad-%ea%b7%bc%ec%b2%98-%eb%a7%9b%ec%a7%91-best-10/\",\n",
        "    \"https://www.xn--hq1bn9iz0nvzar4a.net/%ec%a0%9c%ec%a3%bc%eb%8f%84-%eb%a8%b9%ea%b1%b0%eb%a6%ac-best-10/\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1716702527044
        },
        "id": "12PLolMg_FBH",
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# 4. URL loader 생성-데이터 읽어오기\n",
        "from langchain.document_loaders import UnstructuredURLLoader\n",
        "\n",
        "loader = UnstructuredURLLoader(urls=urls)\n",
        "data = loader.load()\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1716702577238
        },
        "id": "8ECxj4xg_FBH",
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# 6. Text Split(GPT API Token Limit)\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, \n",
        "                                               chunk_overlap=100,\n",
        "                                               separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"],)\n",
        "doc = text_splitter.split_documents(data)\n",
        "doc"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### 참고 링크\n",
        "* [Understanding LangChain's RecursiveCharacterTextSplitter](https://dev.to/eteimz/understanding-langchains-recursivecharactertextsplitter-2846)  \n",
        "* [Chunkerizer 테스터기](https://chunkerizer.streamlit.app)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1716702589779
        },
        "id": "SbZWItYx_FBH"
      },
      "outputs": [],
      "source": [
        "# 6. Vetor Store에 텍스트 벡터값 저장(검색가능함)\n",
        "\n",
        "from langchain_openai import AzureOpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "# 임베딩 모델 생성\n",
        "embedding_model = AzureOpenAIEmbeddings(\n",
        "    azure_deployment=\"text-embedding-ada-002\",\n",
        ")\n",
        "\n",
        "# 문서 -> 벡터 변환\n",
        "vectorstore = Chroma.from_documents(doc, embedding_model)\n",
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})\n",
        "\n",
        "# retriever = vectorstore.as_retriever(\n",
        "#     search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.33}\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1716702591887
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "vectorstore.similarity_search_with_score(\"두부\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1716702604746
        },
        "id": "cUQyT2wV_FBI",
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# 7. OpenAI LLM(Chat Model 연결)\n",
        "\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "\n",
        "chat_llm = AzureChatOpenAI(\n",
        "    deployment_name=\"gpt-35-turbo\",\n",
        "    max_tokens=512,\n",
        "    temperature=0.2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1716702605892
        },
        "id": "1w23KOS0_FBI",
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# 8. Chain 연결 without LCEL\n",
        "\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=chat_llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1716702610667
        },
        "id": "zhVP7Ukj_FBI",
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# 9. 질의\n",
        "query1 = {\"query\" : \"갈치 식당 소개해줘\"}\n",
        "query2 = {\"query\" : \"두부 요리 파는 곳 있어?\"}\n",
        "query3 = {\"query\" : \"제갈양 식당 유명해?\"}\n",
        "\n",
        "queries = [query1, query2, query3]\n",
        "\n",
        "\n",
        "from langchain.callbacks import get_openai_callback\n",
        "\n",
        "with get_openai_callback() as cb:\n",
        "    result = qa_chain.batch(queries)\n",
        "    print(result)\n",
        "    print(cb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1716702628090
        }
      },
      "outputs": [],
      "source": [
        "# 10. Custom Prompt\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "custom_template = '''아래 자료를 기반으로 사용자 질문에 답변한다.\n",
        "자료에 내용이 없는 경우 모른다고하고, 내용을 지어내지 않는다.\n",
        "\n",
        "* 자료 : {context}\n",
        "* 사용자 질문 : {question}\n",
        "'''\n",
        "custom_prompt = PromptTemplate(\n",
        "    template=custom_template,\n",
        "    input_variables=[\n",
        "        'context',\n",
        "        'question',\n",
        "    ]\n",
        ")\n",
        "\n",
        "new_chain = RetrievalQA.from_chain_type(llm=chat_llm,\n",
        "                                        chain_type=\"stuff\",\n",
        "                                        retriever=retriever,\n",
        "                                        return_source_documents=False,\n",
        "                                        chain_type_kwargs={\"prompt\": custom_prompt})\n",
        "\n",
        "new_result = new_chain.batch(queries)\n",
        "print(new_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1716702634208
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# 11. Chain 연결(LCEL)\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "# 검색된 문서를 string으로 변환 \n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
        "\n",
        "lcel_chain = (\n",
        "        {\n",
        "        \"context\": retriever | format_docs,\n",
        "        \"question\": RunnablePassthrough() # RunnablePassthrough : 데이터를 그대로 전달\n",
        "    }\n",
        "    | custom_prompt\n",
        "    | chat_llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "lcel_chain.invoke(\"서울 맛집 알려줘\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1716702641386
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# 여러개 질문 한번에 하기\n",
        "\n",
        "lcel_queries = [\"갈치 식당 소개해줘\", \"두부 요리 파는 곳 있어?\", \"제갈양 식당 유명해?\"]\n",
        "\n",
        "lcel_chain.batch(lcel_queries)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
