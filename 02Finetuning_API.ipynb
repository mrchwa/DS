{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Finetuning API 호출\n",
        "**2024 삼성전자 무선사업부 생성형 AI 교육**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. API Key 설정\n",
        "2. 파일 변환\n",
        "3. 파일 업로드\n",
        "4. Finetuning 작업 요청\n",
        "5. 작업 진행상황 확인 \n",
        "6. 모델명 확인\n",
        "7. 모델 사용 및 비교"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 관련 링크\n",
        "- [OpenAI FineTuning Docs](https://platform.openai.com/docs/guides/fine-tuning)\n",
        "- [OpenAI FineTuning API](https://platform.openai.com/docs/api-reference/fine-tuning)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai # python 3.8 kernel, local에서 사용할 때\n",
        "# &pip install openai => python 3.10 kernel"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting openai\n  Downloading openai-1.35.3-py3-none-any.whl (327 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.4/327.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: sniffio in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from openai) (1.3.1)\nRequirement already satisfied: distro<2,>=1.7.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from openai) (1.9.0)\nRequirement already satisfied: anyio<5,>=3.5.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from openai) (4.3.0)\nRequirement already satisfied: tqdm>4 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from openai) (4.66.2)\nRequirement already satisfied: httpx<1,>=0.23.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from openai) (0.27.0)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from openai) (4.12.2)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from openai) (1.10.15)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\nRequirement already satisfied: idna>=2.8 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\nRequirement already satisfied: certifi in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2022.9.24)\nRequirement already satisfied: httpcore==1.* in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\nRequirement already satisfied: h11<0.15,>=0.13 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\nInstalling collected packages: openai\nSuccessfully installed openai-1.35.3\n"
        }
      ],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 환경 설정\n",
        "\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "# 환경 변수 설정 - Finetuning\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-mnjdCgEPkq1DCQ6oGvHyT3BlbkFJikgeB1O23L1ttMnAHRYu\"\n",
        "\n",
        "client = OpenAI()"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1719211559502
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Finetuning Completion Model "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 파일 변환( csv -> jsonl)\n",
        "\n",
        "!openai tools fine_tunes.prepare_data --file FT_InitialsGame_Train.csv --quiet"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Analyzing...\n\n- Based on your file extension, your file is formatted as a CSV file\n- Your file contains 220 prompt-completion pairs\n- There are 12 duplicated prompt-completion sets. These are rows: [112, 120, 198, 200, 203, 204, 205, 208, 209, 214, 216, 217]\n- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n- Your data does not contain a common ending at the end of your completions. Having a common ending string appended to the end of the completion makes it clearer to the fine-tuned model where the completion should end. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples.\n- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n\nBased on the analysis we will perform the following actions:\n- [Necessary] Your format `CSV` will be converted to `JSONL`\n- [Recommended] Remove 12 duplicate rows [Y/n]: Y\n- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: Y\n/anaconda/envs/azureml_py38/lib/python3.9/site-packages/openai/lib/_validators.py:227: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  x[\"prompt\"] += suffix\n- [Recommended] Add a suffix ending `\\n` to all completions [Y/n]: Y\n/anaconda/envs/azureml_py38/lib/python3.9/site-packages/openai/lib/_validators.py:375: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  x[\"completion\"] += suffix\n- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: Y\n/anaconda/envs/azureml_py38/lib/python3.9/site-packages/openai/lib/_validators.py:410: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  x[\"completion\"] = x[\"completion\"].apply(lambda s: (\"\" if s.startswith(\" \") else \" \") + s)\n\n\nYour data will be written to a new JSONL file. Proceed [Y/n]: Y\n\nWrote modified file to `FT_InitialsGame_Train_prepared.jsonl`\nFeel free to take a look!\n\nNow use that file when fine-tuning:\n> openai api fine_tunes.create -t \"FT_InitialsGame_Train_prepared.jsonl\"\n\nAfter you’ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"\\n\"]` so that the generated texts ends at the expected place.\nOnce your model starts training, it'll approximately take 15.41 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1719212812370
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 파일 업로드\n",
        "\n",
        "training_file_name = \"FT_InitialsGame_Train_prepared.jsonl\"\n",
        "\n",
        "training_response = client.files.create(\n",
        "    file=open(training_file_name, \"rb\"), \n",
        "    purpose=\"fine-tune\"\n",
        ")\n",
        "\n",
        "training_file_id = training_response.id\n",
        "\n",
        "print(training_file_id)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "file-R9Tzyl02CyIy0rCGCd0d0wMS\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1719213541068
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Finetning 작업 요청\n",
        "\n",
        "response = client.fine_tuning.jobs.create(\n",
        "    training_file=training_file_id,\n",
        "    model=\"davinci-002\", #babbage-002, davinci가 좋아\n",
        "    suffix=\"CGY-31\",\n",
        "    hyperparameters={\"n_epochs\":4} # 에포크 수 : 데이터를 몇번 반복 학습할 것인가?\n",
        ")\n",
        "\n",
        "job_id = response.id\n",
        "\n",
        "print(job_id)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "ftjob-qzr0uFJb9mdSVHS9HXWsZgMB\n"
        }
      ],
      "execution_count": 93,
      "metadata": {
        "gather": {
          "logged": 1719216716091
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. 작업 진행상황 확인\n",
        "\n",
        "model_response = client.fine_tuning.jobs.retrieve(job_id)\n",
        "fine_tuned_model_status = model_response.status\n",
        "print(fine_tuned_model_status)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "succeeded\n"
        }
      ],
      "execution_count": 98,
      "metadata": {
        "gather": {
          "logged": 1719217821789
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. 작업 완료된 모델명 확인\n",
        "\n",
        "response = client.fine_tuning.jobs.retrieve(job_id)\n",
        "fine_tuned_model_id = response.fine_tuned_model\n",
        "\n",
        "print(\"Fine-tuned model ID:\", fine_tuned_model_id)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Fine-tuned model ID: ft:davinci-002:mijeongjeon:cgy-31:9dZDarc2\n"
        }
      ],
      "execution_count": 99,
      "metadata": {
        "gather": {
          "logged": 1719217825180
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7-1. 베이스 모델 사용\n",
        "\n",
        "completion = client.completions.create(\n",
        "    model=\"gpt-3.5-turbo-instruct\",\n",
        "    temperature=0.5,\n",
        "    max_tokens=10,\n",
        "    stop=[\"\\n\"],\n",
        "    prompt=\"ㅎㅎ ->\"\n",
        ")\n",
        "\n",
        "completion.choices[0].text"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 27,
          "data": {
            "text/plain": "' ㅎㅎ'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1719214077795
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7-2. Finetuned 모델 사용\n",
        "\n",
        "completion = client.completions.create(\n",
        "    model=\"ft:davinci-002:mijeongjeon:cgy-31:9dZDarc2\",\n",
        "    temperature=0.5,\n",
        "    max_tokens=10,\n",
        "    stop=[\"\\n\"],\n",
        "    prompt=\"ㄸㅎ ->\"\n",
        ")\n",
        "\n",
        "completion.choices[0].text"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 108,
          "data": {
            "text/plain": "' 두툼'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 108,
      "metadata": {
        "gather": {
          "logged": 1719217988121
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Finetuning ChatCompletion Model "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. 파일 업로드\n",
        "\n",
        "chat_training_file_name = \"FT_Food_Info.jsonl\"\n",
        "\n",
        "chat_training_response = client.files.create(\n",
        "    file=open(chat_training_file_name, \"rb\"),\n",
        "    purpose=\"fine-tune\"\n",
        ")\n",
        "\n",
        "chat_training_file_id = chat_training_response.id\n",
        "print(chat_training_file_id)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "file-uwyrlQixwjnrUdNBUGou7TlF\n"
        }
      ],
      "execution_count": 52,
      "metadata": {
        "gather": {
          "logged": 1719214708325
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. 작업 요청\n",
        "chat_response = client.fine_tuning.jobs.create(\n",
        "    training_file=chat_training_file_id,\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    suffix=\"CGY-31\",\n",
        "    hyperparameters={\"n_epochs\":4}\n",
        ")\n",
        "\n",
        "chat_job_id = chat_response.id\n",
        "\n",
        "print(chat_job_id)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "ftjob-jAVmO5zbQ2BWOQCrxVnYrPk0\n"
        }
      ],
      "execution_count": 92,
      "metadata": {
        "gather": {
          "logged": 1719216624611
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. 작업 진행상황 확인\n",
        "\n",
        "chat_model_response = client.fine_tuning.jobs.retrieve(chat_job_id)\n",
        "chat_fine_tuned_model_status = chat_model_response.status\n",
        "print(chat_fine_tuned_model_status)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "succeeded\n"
        }
      ],
      "execution_count": 100,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719217832459
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. 작업 완료된 모델명 확인\n",
        "\n",
        "chat_response = client.fine_tuning.jobs.retrieve(chat_job_id)\n",
        "chat_fine_tuned_model_id = chat_response.fine_tuned_model\n",
        "\n",
        "print(\"Fine-tuned model ID:\", chat_fine_tuned_model_id)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Fine-tuned model ID: ft:gpt-3.5-turbo-0125:mijeongjeon:cgy-31:9dZB1fyB\n"
        }
      ],
      "execution_count": 101,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719217834943
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 12-1. Base 모델 사용\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\":\"system\", \"content\":\"먹을 수 있는 음식 이름을 알려주면 칼로리양과 주요 영양소 탄수화물, 단백질, 지방 함량을 알려주고 음식 이모지를 붙여주는 친절한 도우미\"},\n",
        "        {\"role\":\"user\", \"content\":\"핸드폰\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "죄송합니다, 핸드폰은 먹을 수 있는 음식이 아닙니다. 혹시 다른 음식에 대해 알고 싶으신가요?\n"
        }
      ],
      "execution_count": 71,
      "metadata": {
        "gather": {
          "logged": 1719214976685
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 12-2. Finetuned 모델 사용\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"ft:gpt-3.5-turbo-0125:mijeongjeon:cgy-31:9dZB1fyB\",\n",
        "    messages=[\n",
        "        {\"role\":\"system\", \"content\":\"먹을 수 있는 음식 이름을 알려주면 칼로리양과 주요 영양소 탄수화물, 단백질, 지방 함량을 알려주고 음식 이모지를 붙여주는 친절한 도우미\"},\n",
        "        {\"role\":\"user\", \"content\":\"샤워도우브레드\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "샤워도우브레드 1개(80g)는 210kcal로, 탄수화물 38g, 단백질 6g, 지방 4g이 들어있어요🍞\n"
        }
      ],
      "execution_count": 103,
      "metadata": {
        "gather": {
          "logged": 1719217939125
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}