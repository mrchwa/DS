{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Finetuning API í˜¸ì¶œ\n",
        "**2024 ì‚¼ì„±ì „ì ë¬´ì„ ì‚¬ì—…ë¶€ ìƒì„±í˜• AI êµìœ¡**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. API Key ì„¤ì •\n",
        "2. íŒŒì¼ ë³€í™˜\n",
        "3. íŒŒì¼ ì—…ë¡œë“œ\n",
        "4. Finetuning ì‘ì—… ìš”ì²­\n",
        "5. ì‘ì—… ì§„í–‰ìƒí™© í™•ì¸ \n",
        "6. ëª¨ë¸ëª… í™•ì¸\n",
        "7. ëª¨ë¸ ì‚¬ìš© ë° ë¹„êµ"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ê´€ë ¨ ë§í¬\n",
        "- [OpenAI FineTuning Docs](https://platform.openai.com/docs/guides/fine-tuning)\n",
        "- [OpenAI FineTuning API](https://platform.openai.com/docs/api-reference/fine-tuning)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai # python 3.8 kernel, localì—ì„œ ì‚¬ìš©í•  ë•Œ\n",
        "# &pip install openai => python 3.10 kernel"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting openai\n  Downloading openai-1.35.3-py3-none-any.whl (327 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m327.4/327.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: sniffio in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from openai) (1.3.1)\nRequirement already satisfied: distro<2,>=1.7.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from openai) (1.9.0)\nRequirement already satisfied: anyio<5,>=3.5.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from openai) (4.3.0)\nRequirement already satisfied: tqdm>4 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from openai) (4.66.2)\nRequirement already satisfied: httpx<1,>=0.23.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from openai) (0.27.0)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from openai) (4.12.2)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from openai) (1.10.15)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\nRequirement already satisfied: idna>=2.8 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\nRequirement already satisfied: certifi in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2022.9.24)\nRequirement already satisfied: httpcore==1.* in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\nRequirement already satisfied: h11<0.15,>=0.13 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\nInstalling collected packages: openai\nSuccessfully installed openai-1.35.3\n"
        }
      ],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. í™˜ê²½ ì„¤ì •\n",
        "\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "# í™˜ê²½ ë³€ìˆ˜ ì„¤ì • - Finetuning\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-mnjdCgEPkq1DCQ6oGvHyT3BlbkFJikgeB1O23L1ttMnAHRYu\"\n",
        "\n",
        "client = OpenAI()"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1719211559502
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Finetuning Completion Model "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. íŒŒì¼ ë³€í™˜( csv -> jsonl)\n",
        "\n",
        "!openai tools fine_tunes.prepare_data --file FT_InitialsGame_Train.csv --quiet"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Analyzing...\n\n- Based on your file extension, your file is formatted as a CSV file\n- Your file contains 220 prompt-completion pairs\n- There are 12 duplicated prompt-completion sets. These are rows: [112, 120, 198, 200, 203, 204, 205, 208, 209, 214, 216, 217]\n- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n- Your data does not contain a common ending at the end of your completions. Having a common ending string appended to the end of the completion makes it clearer to the fine-tuned model where the completion should end. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples.\n- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n\nBased on the analysis we will perform the following actions:\n- [Necessary] Your format `CSV` will be converted to `JSONL`\n- [Recommended] Remove 12 duplicate rows [Y/n]: Y\n- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: Y\n/anaconda/envs/azureml_py38/lib/python3.9/site-packages/openai/lib/_validators.py:227: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  x[\"prompt\"] += suffix\n- [Recommended] Add a suffix ending `\\n` to all completions [Y/n]: Y\n/anaconda/envs/azureml_py38/lib/python3.9/site-packages/openai/lib/_validators.py:375: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  x[\"completion\"] += suffix\n- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: Y\n/anaconda/envs/azureml_py38/lib/python3.9/site-packages/openai/lib/_validators.py:410: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  x[\"completion\"] = x[\"completion\"].apply(lambda s: (\"\" if s.startswith(\" \") else \" \") + s)\n\n\nYour data will be written to a new JSONL file. Proceed [Y/n]: Y\n\nWrote modified file to `FT_InitialsGame_Train_prepared.jsonl`\nFeel free to take a look!\n\nNow use that file when fine-tuning:\n> openai api fine_tunes.create -t \"FT_InitialsGame_Train_prepared.jsonl\"\n\nAfter youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"\\n\"]` so that the generated texts ends at the expected place.\nOnce your model starts training, it'll approximately take 15.41 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1719212812370
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. íŒŒì¼ ì—…ë¡œë“œ\n",
        "\n",
        "training_file_name = \"FT_InitialsGame_Train_prepared.jsonl\"\n",
        "\n",
        "training_response = client.files.create(\n",
        "    file=open(training_file_name, \"rb\"), \n",
        "    purpose=\"fine-tune\"\n",
        ")\n",
        "\n",
        "training_file_id = training_response.id\n",
        "\n",
        "print(training_file_id)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "file-R9Tzyl02CyIy0rCGCd0d0wMS\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1719213541068
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Finetning ì‘ì—… ìš”ì²­\n",
        "\n",
        "response = client.fine_tuning.jobs.create(\n",
        "    training_file=training_file_id,\n",
        "    model=\"davinci-002\", #babbage-002, davinciê°€ ì¢‹ì•„\n",
        "    suffix=\"CGY-31\",\n",
        "    hyperparameters={\"n_epochs\":4} # ì—í¬í¬ ìˆ˜ : ë°ì´í„°ë¥¼ ëª‡ë²ˆ ë°˜ë³µ í•™ìŠµí•  ê²ƒì¸ê°€?\n",
        ")\n",
        "\n",
        "job_id = response.id\n",
        "\n",
        "print(job_id)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "ftjob-qzr0uFJb9mdSVHS9HXWsZgMB\n"
        }
      ],
      "execution_count": 93,
      "metadata": {
        "gather": {
          "logged": 1719216716091
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. ì‘ì—… ì§„í–‰ìƒí™© í™•ì¸\n",
        "\n",
        "model_response = client.fine_tuning.jobs.retrieve(job_id)\n",
        "fine_tuned_model_status = model_response.status\n",
        "print(fine_tuned_model_status)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "succeeded\n"
        }
      ],
      "execution_count": 98,
      "metadata": {
        "gather": {
          "logged": 1719217821789
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. ì‘ì—… ì™„ë£Œëœ ëª¨ë¸ëª… í™•ì¸\n",
        "\n",
        "response = client.fine_tuning.jobs.retrieve(job_id)\n",
        "fine_tuned_model_id = response.fine_tuned_model\n",
        "\n",
        "print(\"Fine-tuned model ID:\", fine_tuned_model_id)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Fine-tuned model ID: ft:davinci-002:mijeongjeon:cgy-31:9dZDarc2\n"
        }
      ],
      "execution_count": 99,
      "metadata": {
        "gather": {
          "logged": 1719217825180
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7-1. ë² ì´ìŠ¤ ëª¨ë¸ ì‚¬ìš©\n",
        "\n",
        "completion = client.completions.create(\n",
        "    model=\"gpt-3.5-turbo-instruct\",\n",
        "    temperature=0.5,\n",
        "    max_tokens=10,\n",
        "    stop=[\"\\n\"],\n",
        "    prompt=\"ã…ã… ->\"\n",
        ")\n",
        "\n",
        "completion.choices[0].text"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 27,
          "data": {
            "text/plain": "' ã…ã…'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1719214077795
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7-2. Finetuned ëª¨ë¸ ì‚¬ìš©\n",
        "\n",
        "completion = client.completions.create(\n",
        "    model=\"ft:davinci-002:mijeongjeon:cgy-31:9dZDarc2\",\n",
        "    temperature=0.5,\n",
        "    max_tokens=10,\n",
        "    stop=[\"\\n\"],\n",
        "    prompt=\"ã„¸ã… ->\"\n",
        ")\n",
        "\n",
        "completion.choices[0].text"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 108,
          "data": {
            "text/plain": "' ë‘íˆ¼'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 108,
      "metadata": {
        "gather": {
          "logged": 1719217988121
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Finetuning ChatCompletion Model "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. íŒŒì¼ ì—…ë¡œë“œ\n",
        "\n",
        "chat_training_file_name = \"FT_Food_Info.jsonl\"\n",
        "\n",
        "chat_training_response = client.files.create(\n",
        "    file=open(chat_training_file_name, \"rb\"),\n",
        "    purpose=\"fine-tune\"\n",
        ")\n",
        "\n",
        "chat_training_file_id = chat_training_response.id\n",
        "print(chat_training_file_id)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "file-uwyrlQixwjnrUdNBUGou7TlF\n"
        }
      ],
      "execution_count": 52,
      "metadata": {
        "gather": {
          "logged": 1719214708325
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. ì‘ì—… ìš”ì²­\n",
        "chat_response = client.fine_tuning.jobs.create(\n",
        "    training_file=chat_training_file_id,\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    suffix=\"CGY-31\",\n",
        "    hyperparameters={\"n_epochs\":4}\n",
        ")\n",
        "\n",
        "chat_job_id = chat_response.id\n",
        "\n",
        "print(chat_job_id)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "ftjob-jAVmO5zbQ2BWOQCrxVnYrPk0\n"
        }
      ],
      "execution_count": 92,
      "metadata": {
        "gather": {
          "logged": 1719216624611
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. ì‘ì—… ì§„í–‰ìƒí™© í™•ì¸\n",
        "\n",
        "chat_model_response = client.fine_tuning.jobs.retrieve(chat_job_id)\n",
        "chat_fine_tuned_model_status = chat_model_response.status\n",
        "print(chat_fine_tuned_model_status)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "succeeded\n"
        }
      ],
      "execution_count": 100,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719217832459
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. ì‘ì—… ì™„ë£Œëœ ëª¨ë¸ëª… í™•ì¸\n",
        "\n",
        "chat_response = client.fine_tuning.jobs.retrieve(chat_job_id)\n",
        "chat_fine_tuned_model_id = chat_response.fine_tuned_model\n",
        "\n",
        "print(\"Fine-tuned model ID:\", chat_fine_tuned_model_id)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Fine-tuned model ID: ft:gpt-3.5-turbo-0125:mijeongjeon:cgy-31:9dZB1fyB\n"
        }
      ],
      "execution_count": 101,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719217834943
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 12-1. Base ëª¨ë¸ ì‚¬ìš©\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\":\"system\", \"content\":\"ë¨¹ì„ ìˆ˜ ìˆëŠ” ìŒì‹ ì´ë¦„ì„ ì•Œë ¤ì£¼ë©´ ì¹¼ë¡œë¦¬ì–‘ê³¼ ì£¼ìš” ì˜ì–‘ì†Œ íƒ„ìˆ˜í™”ë¬¼, ë‹¨ë°±ì§ˆ, ì§€ë°© í•¨ëŸ‰ì„ ì•Œë ¤ì£¼ê³  ìŒì‹ ì´ëª¨ì§€ë¥¼ ë¶™ì—¬ì£¼ëŠ” ì¹œì ˆí•œ ë„ìš°ë¯¸\"},\n",
        "        {\"role\":\"user\", \"content\":\"í•¸ë“œí°\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "ì£„ì†¡í•©ë‹ˆë‹¤, í•¸ë“œí°ì€ ë¨¹ì„ ìˆ˜ ìˆëŠ” ìŒì‹ì´ ì•„ë‹™ë‹ˆë‹¤. í˜¹ì‹œ ë‹¤ë¥¸ ìŒì‹ì— ëŒ€í•´ ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”?\n"
        }
      ],
      "execution_count": 71,
      "metadata": {
        "gather": {
          "logged": 1719214976685
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 12-2. Finetuned ëª¨ë¸ ì‚¬ìš©\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"ft:gpt-3.5-turbo-0125:mijeongjeon:cgy-31:9dZB1fyB\",\n",
        "    messages=[\n",
        "        {\"role\":\"system\", \"content\":\"ë¨¹ì„ ìˆ˜ ìˆëŠ” ìŒì‹ ì´ë¦„ì„ ì•Œë ¤ì£¼ë©´ ì¹¼ë¡œë¦¬ì–‘ê³¼ ì£¼ìš” ì˜ì–‘ì†Œ íƒ„ìˆ˜í™”ë¬¼, ë‹¨ë°±ì§ˆ, ì§€ë°© í•¨ëŸ‰ì„ ì•Œë ¤ì£¼ê³  ìŒì‹ ì´ëª¨ì§€ë¥¼ ë¶™ì—¬ì£¼ëŠ” ì¹œì ˆí•œ ë„ìš°ë¯¸\"},\n",
        "        {\"role\":\"user\", \"content\":\"ìƒ¤ì›Œë„ìš°ë¸Œë ˆë“œ\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "ìƒ¤ì›Œë„ìš°ë¸Œë ˆë“œ 1ê°œ(80g)ëŠ” 210kcalë¡œ, íƒ„ìˆ˜í™”ë¬¼ 38g, ë‹¨ë°±ì§ˆ 6g, ì§€ë°© 4gì´ ë“¤ì–´ìˆì–´ìš”ğŸ\n"
        }
      ],
      "execution_count": 103,
      "metadata": {
        "gather": {
          "logged": 1719217939125
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}