{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# LangChain Basic\n",
        "**2024 삼성전자 무선사업부 생성형 AI 교육**"
      ],
      "metadata": {
        "id": "w2GM8vtc_FBB",
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "1. 패키지 설치\n",
        "2. 기본 패키지 & 환경 설정\n",
        "3. LLM\n",
        "4. Embedding\n",
        "5. Prompt Template\n",
        "6. Fewshot Prompt Template\n",
        "7. Chain + Memory "
      ],
      "metadata": {
        "id": "dzXcYq79_FBE",
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install tiktoken\n",
        "%pip install langchain\n",
        "%pip install -U langchain-openai\n",
        "%pip install langchain_community\n",
        "%pip install langchain_core"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting tiktoken\n  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nCollecting regex>=2022.1.18 (from tiktoken)\n  Downloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tiktoken) (2.32.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.2.1)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2024.6.2)\nDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (775 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m775.1/775.1 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: regex, tiktoken\nSuccessfully installed regex-2024.5.15 tiktoken-0.7.0\nNote: you may need to restart the kernel to use updated packages.\nCollecting langchain\n  Downloading langchain-0.2.5-py3-none-any.whl.metadata (7.0 kB)\nRequirement already satisfied: PyYAML>=5.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain) (2.0.30)\nCollecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n  Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\nCollecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\nCollecting langchain-core<0.3.0,>=0.2.7 (from langchain)\n  Downloading langchain_core-0.2.9-py3-none-any.whl.metadata (6.0 kB)\nCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n  Downloading langchain_text_splitters-0.2.1-py3-none-any.whl.metadata (2.2 kB)\nCollecting langsmith<0.2.0,>=0.1.17 (from langchain)\n  Downloading langsmith-0.1.82-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy<2,>=1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain) (1.26.4)\nRequirement already satisfied: pydantic<3,>=1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain) (2.7.4)\nRequirement already satisfied: requests<3,>=2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain) (2.32.3)\nCollecting tenacity<9.0.0,>=8.1.0 (from langchain)\n  Downloading tenacity-8.4.2-py3-none-any.whl.metadata (1.2 kB)\nRequirement already satisfied: aiosignal>=1.1.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\nCollecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nCollecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\nCollecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.7->langchain)\n  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: packaging<25,>=23.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.7->langchain) (24.0)\nCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n  Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.18.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.18.4)\nRequirement already satisfied: typing-extensions>=4.6.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.2.1)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.6.2)\nRequirement already satisfied: greenlet!=0.4.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\nCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.7->langchain)\n  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\nDownloading langchain-0.2.5-py3-none-any.whl (974 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.6/974.6 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\nDownloading langchain_core-0.2.9-py3-none-any.whl (321 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.8/321.8 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.2.1-py3-none-any.whl (23 kB)\nDownloading langsmith-0.1.82-py3-none-any.whl (127 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.4/127.4 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tenacity-8.4.2-py3-none-any.whl (28 kB)\nDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\nDownloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\nInstalling collected packages: tenacity, orjson, multidict, jsonpointer, async-timeout, yarl, jsonpatch, langsmith, aiohttp, langchain-core, langchain-text-splitters, langchain\nSuccessfully installed aiohttp-3.9.5 async-timeout-4.0.3 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.5 langchain-core-0.2.9 langchain-text-splitters-0.2.1 langsmith-0.1.82 multidict-6.0.5 orjson-3.10.5 tenacity-8.4.2 yarl-1.9.4\nNote: you may need to restart the kernel to use updated packages.\nCollecting langchain-openai\n  Downloading langchain_openai-0.1.9-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: langchain-core<0.3,>=0.2.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain-openai) (0.2.9)\nRequirement already satisfied: openai<2.0.0,>=1.26.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain-openai) (1.35.3)\nRequirement already satisfied: tiktoken<1,>=0.7 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain-openai) (0.7.0)\nRequirement already satisfied: PyYAML>=5.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (6.0.1)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (1.33)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.75 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (0.1.82)\nRequirement already satisfied: packaging<25,>=23.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (24.0)\nRequirement already satisfied: pydantic<3,>=1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (2.7.4)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (8.4.2)\nRequirement already satisfied: anyio<5,>=3.5.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (4.4.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (0.27.0)\nRequirement already satisfied: sniffio in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (1.3.1)\nRequirement already satisfied: tqdm>4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (4.66.4)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (4.12.2)\nRequirement already satisfied: regex>=2022.1.18 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.5.15)\nRequirement already satisfied: requests>=2.26.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\nRequirement already satisfied: idna>=2.8 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.26.0->langchain-openai) (3.7)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.26.0->langchain-openai) (1.2.0)\nRequirement already satisfied: certifi in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain-openai) (2024.6.2)\nRequirement already satisfied: httpcore==1.* in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain-openai) (1.0.5)\nRequirement already satisfied: h11<0.15,>=0.13 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain-openai) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.2->langchain-openai) (3.0.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.2->langchain-openai) (3.10.5)\nRequirement already satisfied: annotated-types>=0.4.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.2->langchain-openai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.18.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.2->langchain-openai) (2.18.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.1)\nDownloading langchain_openai-0.1.9-py3-none-any.whl (40 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: langchain-openai\nSuccessfully installed langchain-openai-0.1.9\nNote: you may need to restart the kernel to use updated packages.\nCollecting langchain_community\n  Downloading langchain_community-0.2.5-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: PyYAML>=5.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain_community) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain_community) (2.0.30)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain_community) (3.9.5)\nCollecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: langchain<0.3.0,>=0.2.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain_community) (0.2.5)\nRequirement already satisfied: langchain-core<0.3.0,>=0.2.7 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain_community) (0.2.9)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain_community) (0.1.82)\nRequirement already satisfied: numpy<2,>=1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain_community) (1.26.4)\nRequirement already satisfied: requests<3,>=2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain_community) (2.32.3)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain_community) (8.4.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\nCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.5->langchain_community) (0.2.1)\nRequirement already satisfied: pydantic<3,>=1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.5->langchain_community) (2.7.4)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.7->langchain_community) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.7->langchain_community) (24.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2.2.1)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2024.6.2)\nRequirement already satisfied: typing-extensions>=4.6.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.12.2)\nRequirement already satisfied: greenlet!=0.4.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\nRequirement already satisfied: jsonpointer>=1.9 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.7->langchain_community) (3.0.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.5->langchain_community) (0.7.0)\nRequirement already satisfied: pydantic-core==2.18.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.5->langchain_community) (2.18.4)\nCollecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\nDownloading langchain_community-0.2.5-py3-none-any.whl (2.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\nDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\nDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\nInstalling collected packages: mypy-extensions, typing-inspect, dataclasses-json, langchain_community\nSuccessfully installed dataclasses-json-0.6.7 langchain_community-0.2.5 mypy-extensions-1.0.0 typing-inspect-0.9.0\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: langchain_core in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (0.2.9)\nRequirement already satisfied: PyYAML>=5.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain_core) (6.0.1)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain_core) (1.33)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.75 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain_core) (0.1.82)\nRequirement already satisfied: packaging<25,>=23.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain_core) (24.0)\nRequirement already satisfied: pydantic<3,>=1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain_core) (2.7.4)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain_core) (8.4.2)\nRequirement already satisfied: jsonpointer>=1.9 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain_core) (3.0.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.75->langchain_core) (3.10.5)\nRequirement already satisfied: requests<3,>=2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.75->langchain_core) (2.32.3)\nRequirement already satisfied: annotated-types>=0.4.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pydantic<3,>=1->langchain_core) (0.7.0)\nRequirement already satisfied: pydantic-core==2.18.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pydantic<3,>=1->langchain_core) (2.18.4)\nRequirement already satisfied: typing-extensions>=4.6.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pydantic<3,>=1->langchain_core) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain_core) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain_core) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain_core) (2.2.1)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain_core) (2024.6.2)\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": false,
        "gather": {
          "logged": 1700910339407
        },
        "id": "9EbvSmJl_FBE",
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "outputId": "8e46b7f4-2875-4286-8a0d-4c78481249b9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 기본 패키지 설정 & AzureOpenAI 환경설정\n",
        "\n",
        "# 환경 변수 설정!! \n",
        "import os\n",
        "import langchain\n",
        "\n",
        "from config_azure import (\n",
        "    AZURE_OPENAI_API_VERSION,\n",
        "    AZURE_OPENAI_ENDPOINT,\n",
        "    AZURE_OPENAI_KEY\n",
        ")\n",
        "# lagchain 사용시 반드시 환경변수 값 사용!!\n",
        "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = AZURE_OPENAI_KEY\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = AZURE_OPENAI_ENDPOINT\n",
        "os.environ[\"OPENAI_API_VERSION\"] = AZURE_OPENAI_API_VERSION"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1719288956526
        },
        "id": "Ua4tsQUd_FBG",
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3-1. OpenAI LLM(CompletionModel 연결)\n",
        "\n",
        "from langchain_openai import AzureOpenAI\n",
        "\n",
        "com_llm = AzureOpenAI(\n",
        "    azure_deployment=\"gpt-35-turbo-instruct\",\n",
        "    max_tokens=128,\n",
        "    temperature=0.9)\n",
        "\n",
        "com_llm_low = AzureOpenAI(\n",
        "    azure_deployment=\"gpt-35-turbo-instruct\",\n",
        "    max_tokens=128,\n",
        "    temperature=0.2)"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "gather": {
          "logged": 1719289052552
        },
        "id": "_1tw9gbs6BX1",
        "outputId": "b15d2181-dd2f-42b0-f602-eff80e906552"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "com_llm.invoke(\"오늘 저녁 메뉴는\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "' 뭐로 하지...?\\n\\n저녁 메뉴는 비빔밥이나 불고기와 밥, 김치찌개 등 한식 메뉴를 준비하는 것도 좋을 것 같습니다. 또는 스파게티나 피자, 샐러드 등 다양한 서양 요리도 좋은 선택일 수 있습니다. 차가운 날씨이므로 따뜻한 스프나 찌'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1719289079355
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "com_llm_low.invoke(\"안녕\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "'하세요. 저는 21살의 대학생입니다. 현재는 경영학을 전공하고 있으며, 취미로는 영화 감상과 음악 감상을 좋아합니다. 또한 여행을 다니는 것도 즐겨하는 편이며, 다양한 문화와 사람들을 만나는 것을 좋아합니다. 또한 새로운 도전을 좋아하고 적'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719289577351
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3-2. OpenAI LLM(Chat Model 연결)\n",
        "\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "\n",
        "chat_llm = AzureChatOpenAI(\n",
        "    deployment_name=\"gpt-35-turbo\",\n",
        "    max_tokens=256,\n",
        "    temperature=0.9,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1719289249411
        },
        "id": "VMWlGkXF_FBH",
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_llm.invoke(\"오늘 저녁 메뉴는\").content"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "'저는 AI이기 때문에 저녁 메뉴를 정할 수는 없지만, 다양한 영양소가 포함된 채소와 단백질이 들어간 건강한 식사를 추천합니다. 예를 들어 샐러드와 그릴한 닭가슴살, 혹은 참치와 양배추 샐러드 등이 있습니다. 또는 느린 요리 인스턴트 포트로 만든 채소 수프와 간단한 샐러드로도 나쁘지 않습니다.'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1719289261773
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3-3. Chat llm 사용\n",
        "\n",
        "from langchain.schema import (\n",
        "    SystemMessage, # system\n",
        "    AIMessage, # assistant\n",
        "    HumanMessage # user\n",
        ")\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"RPG 게임 캐릭터 재키, 성을 지키는 용감한 용사로 유저의 질문에 반말 구어체로 짧게 답한다\"),\n",
        "    HumanMessage(content=\"안녕?\"),\n",
        "    AIMessage(content=\"용감한 자여, 전설의 성에 온걸 환영한다!\"),\n",
        "    HumanMessage(content=\"너의 이름은 뭐니?\"),\n",
        "    AIMessage(content=\"사람들은 나를 재키라 부르지. 성을 지키는 임무를 맡았으니 무엇이든 나에게 물어보라.\"),\n",
        "    HumanMessage(content=\"용을 만나려면 어떻게해야하지?\"),\n",
        "]\n",
        "\n",
        "chat_llm.invoke(messages).content"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "'용을 만나긴 쉽지 않다. 하지만 미궁이나 광활한 들판, 산과 같은 곳에서 용을 찾을 수 있지. 용의 위치를 정확히 모르더라도 그들의 거대한 날개짓소리나 불길한 포효 소리를 듣고 진심으로 찾아가면 찾을 수 있을거야.'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1719289392032
        },
        "id": "12PLolMg_FBH",
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "com_llm.invoke(messages)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "'\\nAI: 그건 쉽다. 그냥 용의 둥지로 가면 된다. 하지만 그곳은 위험하기 때문에 조심해야 한다.'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719289825467
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4-1. Embedding 모델 연결\n",
        "\n",
        "from langchain_openai import AzureOpenAIEmbeddings\n",
        "\n",
        "embedding_model = AzureOpenAIEmbeddings(\n",
        "    azure_deployment=\"text-embedding-ada-002\",\n",
        ")\n",
        "\n",
        "len(embedding_model.embed_query(\"hello\"))"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "1536"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1719289962787
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4-2. 유사도\n",
        "\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def cos_sim(word1, word2):\n",
        "    em1 = embedding_model.embed_query(word1)\n",
        "    em2 = embedding_model.embed_query(word2)\n",
        "    return dot(em1, em2)/(norm(em1)*norm(em2))"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1719289444806
        },
        "id": "SbZWItYx_FBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cos_sim(\"고양이가 길을 걷는다\",\"?\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 25,
          "data": {
            "text/plain": "0.7413174231520637"
          },
          "metadata": {}
        }
      ],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719292037537
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Chat Prompt Template(Chat Model Prompt)\n",
        "\n",
        "from langchain.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate\n",
        "\n",
        "system_template = \"\"\"\n",
        "한국어 문장을 {output_language}로 번역하는 인공지능.\n",
        "번역된 문장의 한글 발음을 괄호 안에 함께 제공한다.\n",
        "예) Hi(하이), こんにちは(곤니치와)\n",
        "\"\"\"\n",
        "\n",
        "system_message_prompt_template = SystemMessagePromptTemplate.from_template(\n",
        "    system_template)\n",
        "\n",
        "human_template = \"{input_text}\"\n",
        "\n",
        "human_message_prompt_template = HumanMessagePromptTemplate.from_template(human_template)\n",
        "\n",
        "chat_prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [system_message_prompt_template, human_message_prompt_template])\n",
        "\n",
        "final_prompt = chat_prompt_template.format_prompt(output_language=\"일본어\",\n",
        "                          input_text=\"오늘 날씨 정말 좋네요.\").to_messages()\n",
        "\n",
        "print(final_prompt)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[SystemMessage(content='\\n한국어 문장을 일본어로 번역하는 인공지능.\\n번역된 문장의 한글 발음을 괄호 안에 함께 제공한다.\\n예) Hi(하이), こんにちは(곤니치와)\\n'), HumanMessage(content='오늘 날씨 정말 좋네요.')]\n"
        }
      ],
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": false,
        "gather": {
          "logged": 1719292421067
        },
        "id": "cUQyT2wV_FBI",
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "outputId": "fad3b31e-d707-4878-b1e5-957758cbc945"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_llm.invoke(final_prompt).content"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 34,
          "data": {
            "text/plain": "'오늘 날씨는 정말 좋네요.(오늘の天気は本当に良いです。)'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1719292516495
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "com_llm.invoke(final_prompt)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 33,
          "data": {
            "text/plain": "'\\n\\nSystem: 今日の天気は本当にいいですね。(금요일 테마가 통하는 말입니다.), こんいちのてんきはほんとによいですね。(금요일 테마가 통하는 말입니다.)'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 33,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719292501625
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. PromptTemplate ⭐️⭐️⭐️\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "한국어 문장 {input_text}을 {output_language}로 번역하는 인공지능.\n",
        "번역된 문장의 한글 발음을 괄호 안에 함께 제공한다.\n",
        "예) Hi(하이), こんにちは(곤니치와)\n",
        "\"\"\"\n",
        "\n",
        "translate_template = PromptTemplate(\n",
        "    input_variables=[\"input_text\", \"output_language\"],\n",
        "    template=template\n",
        ")\n",
        "\n",
        "final_prompt = translate_template.format_prompt(input_text=\"오늘 날씨가 정말 좋아요\", \n",
        "                                                output_language=\"일본어\").to_messages()\n",
        "print(final_prompt)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[HumanMessage(content='\\n한국어 문장 오늘 날씨가 정말 좋아요을 일본어로 번역하는 인공지능.\\n번역된 문장의 한글 발음을 괄호 안에 함께 제공한다.\\n예) Hi(하이), こんにちは(곤니치와)\\n')]\n"
        }
      ],
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "gather": {
          "logged": 1719292550573
        },
        "id": "HlOmdpRwNgYt",
        "outputId": "7f7f0401-62e6-4878-dea8-60a5f0734204"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_llm.invoke(final_prompt).content"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 39,
          "data": {
            "text/plain": "'오늘 날씨가 정말 좋아요(오늘 날씨가 정말 좋아요) -> 今日の天気は本当に良くています。(きょうのてんきはほんとうによくています。)'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 39,
      "metadata": {
        "gather": {
          "logged": 1719292624021
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6-2. Few shot learning\n",
        "\n",
        "from langchain.prompts import FewShotPromptTemplate\n",
        "# fewshot 예시 문장\n",
        "examples = [\n",
        "    {\"input\": \"영어 : 이 와인 정말 맛있네요\", \"output\": \"This wine is really delicious.(발음:디스 와인 이즈 리얼리 딜리셔스)\"},\n",
        "    {\"input\": \"프랑스어 : 이 와인 정말 맛있네요\", \"output\": \"Ce vin est vraiment délicieux.(발음:세 반 에트랑제 드리슈)\"},\n",
        "    {\"input\": \"독일어 : 이 와인 정말 맛있네요 \", \"output\": \"Dieser Wein schmeckt wirklich lecker.(발음:디저 바인 샴케 비역클러)\"},\n",
        "    {\"input\": \"일본어 : 이 와인 정말 맛있네요\", \"output\": \"このワインは本当においしいですね。(발음:코노 와인와 혼토니 오이시이 데스 네)\"},\n",
        "    {\"input\": \"이태리어 : 이 와인 정말 맛있네요\", \"output\": \"Questo vino è davvero delizioso.(발음:쿼스토 비노 에 디버로 델리조오소)\"},\n",
        "    {\"input\": \"이태리어 : 화장실이 어디인가요?\", \"output\": \"Dov'è il bagno?(발음:도베 이르 바뇨?\"},\n",
        "    {\"input\": \"일본어 : 화장실이 어디인가요?\", \"output\": \"トイレはどこですか？(발음:토이레와 도코데스카?)\"},\n",
        "    {\"input\": \"독일어 : 화장실이 어디인가요?\", \"output\": \"Entschuldigung, wo ist die Toilette?(발음:앤쇨룰디귄, 보이스 디 토일레트?)\"},\n",
        "    {\"input\": \"프랑스어 : 화장실이 어디인가요?\", \"output\": \"Où sont les toilettes?(발음:우 솽 레 투알레트?)\"},\n",
        "    {\"input\": \"영어 : 화장실이 어디인가요?\", \"output\": \"Where is the restroom?(발음:웨어 이즈 더 레스트룸?)\"},\n",
        "]\n",
        "\n",
        "# fewshot 예시 문장+템플릿 결합\n",
        "example_prompt = PromptTemplate(input_variables=[\"input\", \"output\"],\n",
        "                                template=\"문장을 주어진 언어로 번역한다. 번역된 문장의 한국어 발음을 괄호 안에 함께 표기한다. : {input} -> {output}\")\n",
        "\n",
        "fewshot_prompt = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    suffix=\"문장을 주어진 언어로 번역하고 한글 발음을 괄호안에 표기한다.  : {input} -> \",\n",
        "    input_variables=[\"input\"]\n",
        ")\n",
        "\n",
        "final_prompt=fewshot_prompt.format_prompt(input=\"영어 : 날씨가 너무 더워요\").to_messages()\n",
        "print(final_prompt)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[HumanMessage(content=\"문장을 주어진 언어로 번역한다. 번역된 문장의 한국어 발음을 괄호 안에 함께 표기한다. : 영어 : 이 와인 정말 맛있네요 -> This wine is really delicious.(발음:디스 와인 이즈 리얼리 딜리셔스)\\n\\n문장을 주어진 언어로 번역한다. 번역된 문장의 한국어 발음을 괄호 안에 함께 표기한다. : 프랑스어 : 이 와인 정말 맛있네요 -> Ce vin est vraiment délicieux.(발음:세 반 에트랑제 드리슈)\\n\\n문장을 주어진 언어로 번역한다. 번역된 문장의 한국어 발음을 괄호 안에 함께 표기한다. : 독일어 : 이 와인 정말 맛있네요  -> Dieser Wein schmeckt wirklich lecker.(발음:디저 바인 샴케 비역클러)\\n\\n문장을 주어진 언어로 번역한다. 번역된 문장의 한국어 발음을 괄호 안에 함께 표기한다. : 일본어 : 이 와인 정말 맛있네요 -> このワインは本当においしいですね。(발음:코노 와인와 혼토니 오이시이 데스 네)\\n\\n문장을 주어진 언어로 번역한다. 번역된 문장의 한국어 발음을 괄호 안에 함께 표기한다. : 이태리어 : 이 와인 정말 맛있네요 -> Questo vino è davvero delizioso.(발음:쿼스토 비노 에 디버로 델리조오소)\\n\\n문장을 주어진 언어로 번역한다. 번역된 문장의 한국어 발음을 괄호 안에 함께 표기한다. : 이태리어 : 화장실이 어디인가요? -> Dov'è il bagno?(발음:도베 이르 바뇨?\\n\\n문장을 주어진 언어로 번역한다. 번역된 문장의 한국어 발음을 괄호 안에 함께 표기한다. : 일본어 : 화장실이 어디인가요? -> トイレはどこですか？(발음:토이레와 도코데스카?)\\n\\n문장을 주어진 언어로 번역한다. 번역된 문장의 한국어 발음을 괄호 안에 함께 표기한다. : 독일어 : 화장실이 어디인가요? -> Entschuldigung, wo ist die Toilette?(발음:앤쇨룰디귄, 보이스 디 토일레트?)\\n\\n문장을 주어진 언어로 번역한다. 번역된 문장의 한국어 발음을 괄호 안에 함께 표기한다. : 프랑스어 : 화장실이 어디인가요? -> Où sont les toilettes?(발음:우 솽 레 투알레트?)\\n\\n문장을 주어진 언어로 번역한다. 번역된 문장의 한국어 발음을 괄호 안에 함께 표기한다. : 영어 : 화장실이 어디인가요? -> Where is the restroom?(발음:웨어 이즈 더 레스트룸?)\\n\\n문장을 주어진 언어로 번역하고 한글 발음을 괄호안에 표기한다.  : 영어 : 날씨가 너무 더워요 -> \")]\n"
        }
      ],
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "gather": {
          "logged": 1719292955613
        },
        "id": "9epEKSyQFEZQ",
        "outputId": "237be70c-4806-4a67-8726-d47ef99a03d7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# token 확인 하는 방법\n",
        "\n",
        "from langchain.callbacks import get_openai_callback\n",
        "\n",
        "with get_openai_callback() as cb:\n",
        "    chat_llm.invoke(final_prompt).content\n",
        "    print(cb)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Tokens Used: 1051\n\tPrompt Tokens: 1024\n\tCompletion Tokens: 27\nSuccessful Requests: 1\nTotal Cost (USD): $0.00159\n"
        }
      ],
      "execution_count": 53,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719292981446
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_llm.invoke(final_prompt).content"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 48,
          "data": {
            "text/plain": "\"It's too hot today. (발음: 잇츠 투 호트 투데이)\""
          },
          "metadata": {}
        }
      ],
      "execution_count": 48,
      "metadata": {
        "gather": {
          "logged": 1719292790149
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "com_llm.invoke(final_prompt)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 49,
          "data": {
            "text/plain": "' The weather is too hot.(발음:더 웨더 이즈 투 호트) '"
          },
          "metadata": {}
        }
      ],
      "execution_count": 49,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719292795943
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7-1. Chain-PromptTemplate 연결\n",
        "# LangChain without LCEL:\n",
        "\n",
        "from langchain.chains import LLMChain \n",
        "from langchain.schema import StrOutputParser\n",
        "\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# 체인 = 모델 + 프롬프트 + Parser\n",
        "chain = LLMChain(llm=chat_llm, \n",
        "                 prompt=fewshot_prompt,\n",
        "                 output_parser=output_parser)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n  warn_deprecated(\n"
        }
      ],
      "execution_count": 54,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1719293086603
        },
        "id": "LPSmQ8GE_FBJ",
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(\"영어 : 어제는 저녁에 꽤 추웠어요\")['text']"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 56,
          "data": {
            "text/plain": "'Yesterday evening was quite chilly. (발음: 예스터데이 이브닝 와즈 콰이트 칠리)'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 56,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719293162686
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### LangChain Expression Language (LCEL)\n",
        "* [LCEL 공식 문서 바로가기](https://python.langchain.com/v0.1/docs/expression_language/)\n",
        "* [LCEL Parsers 공식 문서](https://python.langchain.com/v0.1/docs/modules/model_io/output_parsers/)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7-2. LCEL(LangChain Express Language) 활용 코드\n",
        "# (model(prompt)) -> output_parser(model(prompt))\n",
        "\n",
        "chain = fewshot_prompt | chat_llm | output_parser\n",
        "com_chain = fewshot_prompt | com_llm | output_parser"
      ],
      "outputs": [],
      "execution_count": 57,
      "metadata": {
        "gather": {
          "logged": 1719293285207
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(\"일본어 : 모두들 감사합니다\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 58,
          "data": {
            "text/plain": "'みんな、ありがとう (발음: 민나, 아리가토우 고자이마스)'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 58,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719293312677
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "com_chain.invoke(\"일본어 : 모두들 감사합니다\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 59,
          "data": {
            "text/plain": "'皆さん、ありがとうございます。(카이산, 아리가토고자이마스.)'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 59,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719293340624
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7-3. Batch : 여러개 인풋 활용\n",
        "\n",
        "input_list = [\n",
        "    {\"input\" : \"영어 : 이 와인 정말 맛있네요\"},\n",
        "    {\"input\" : \"이태리어 : 이 와인 정말 맛있네요\"},\n",
        "    {\"input\" : \"프랑스어 : 이 와인 정말 맛있네요\"}\n",
        "]"
      ],
      "outputs": [],
      "execution_count": 60,
      "metadata": {
        "gather": {
          "logged": 1719293388437
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain.batch(input_list)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 64,
          "data": {
            "text/plain": "['This wine is really delicious. (발음: 디스 와인 이즈 리얼리 딜리셔스)',\n 'Questo vino è davvero delizioso. (발음: 쿼스토 비노 에 디버로 델리조오소)',\n 'Ce vin est vraiment délicieux. (발음: 스 반 에 디리셔)']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 64,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719293530645
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Simple Sequential Chain\n",
        "\n",
        "![](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qrct9oGPZklQSWwlPNKfqQ.png)\n",
        "[Image Reference](https://faun.pub/langchain-in-chains-11-chains-33b9f3c2d217)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 8-1. 두 개 체인 연결 \n",
        "# without LCEL\n",
        "\n",
        "# SimpleSequentialChain: 하나의 input variable 만 사용가능\n",
        "from langchain.chains import SimpleSequentialChain\n",
        "\n",
        "# 첫번째 체인(한국어->외국어)\n",
        "fisrt_chain = LLMChain(llm = chat_llm,\n",
        "                 prompt = fewshot_prompt)\n",
        "\n",
        "# 두번째 체인\n",
        "second_prompt = PromptTemplate(\n",
        "    input_variables=[\"foreign_language\"],\n",
        "    template=\"번역된 문장과 동일한 뜻의 유사 표현 5개와 번역된 문장의 한국어 발음 표기를 괄호 안에 표기한다: {foreign_language}\",\n",
        ")\n",
        "\n",
        "second_chain = LLMChain(llm=chat_llm, prompt=second_prompt)\n",
        "\n",
        "# 두가지 체인 결합\n",
        "overall_chain = SimpleSequentialChain(chains=[fisrt_chain, second_chain], verbose=True)"
      ],
      "outputs": [],
      "execution_count": 65,
      "metadata": {
        "gather": {
          "logged": 1719293645808
        },
        "id": "RQoOOaeaKAxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "overall_chain.invoke(\"영어 : 이 와인 정말 맛있네요\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n\n\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n\u001b[36;1m\u001b[1;3mThis wine is really delicious. (발음: 디스 와인 이즈 리얼리 딜리셔스)\u001b[0m\n\u001b[33;1m\u001b[1;3m1. This wine tastes amazing. (발음: 디스 와인 테이스 아메이징)\n2. I really enjoy the taste of this wine. (발음: 아이 리얼리 인조이 더 테이스트 어브 디스 와인)\n3. This wine is very pleasing to my palate. (발음: 디스 와인 이즈 베리 플리징 투 마이 팰럿)\n4. The flavor of this wine is excellent. (발음: 더 플레이버 어브 디스 와인 이즈 익셀런트)\n5. I find this wine to be quite delicious. (발음: 아이 파인드 디스 와인 투 비 콰이트 딜리셔스)\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 67,
          "data": {
            "text/plain": "{'input': '영어 : 이 와인 정말 맛있네요',\n 'output': '1. This wine tastes amazing. (발음: 디스 와인 테이스 아메이징)\\n2. I really enjoy the taste of this wine. (발음: 아이 리얼리 인조이 더 테이스트 어브 디스 와인)\\n3. This wine is very pleasing to my palate. (발음: 디스 와인 이즈 베리 플리징 투 마이 팰럿)\\n4. The flavor of this wine is excellent. (발음: 더 플레이버 어브 디스 와인 이즈 익셀런트)\\n5. I find this wine to be quite delicious. (발음: 아이 파인드 디스 와인 투 비 콰이트 딜리셔스)'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 67,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719293816064
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 8-2. With LCEL\n",
        "\n",
        "chain1 = fewshot_prompt | chat_llm \n",
        "chain2 = second_prompt | chat_llm \n",
        "\n",
        "overall_chain = chain1 | chain2 | output_parser | line_parse"
      ],
      "outputs": [],
      "execution_count": 71,
      "metadata": {
        "gather": {
          "logged": 1719294245923
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "overall_chain.invoke(\"영어 : 이 와인 정말 맛있네요\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 72,
          "data": {
            "text/plain": "['1. This wine is absolutely delicious. (발음: 디스 와인 이즈 앱솔루트리 딜리셔스)',\n '2. The wine tastes amazing. (발음: 더 와인 테이스트 어메이징)',\n '3. I really enjoy this wine. (발음: 아이 리얼리 인조이 디스 와인)',\n '4. This wine is very tasty. (발음: 디스 와인 이즈 베리 테이스티)',\n '5. The flavor of this wine is excellent. (발음: 더 플레이버 어브 디스 와인 이즈 익셀런트)']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 72,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719294253132
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 줄바꿈 custom parser\n",
        "def line_parse(output) -> str:\n",
        "    lines = output.split('\\n')\n",
        "    return lines"
      ],
      "outputs": [],
      "execution_count": 70,
      "metadata": {
        "gather": {
          "logged": 1719294205243
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SequentialChain\n",
        "![]()"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 9-1. 여러개 인풋 사용 가능한 Sequential Chain \n",
        "# without LCEL\n",
        "\n",
        "from langchain.chains import SequentialChain\n",
        "\n",
        "# 첫번째 체인\n",
        "menu_template = \"\"\"\n",
        "신메뉴 이름 {name}이 제공됩니다.\n",
        "주재료는 {ingredients}입니다.\n",
        "주어진 정보를 바탕으로 배달 서비스에 쓰일 신메뉴 소개글을 100자로 작성하시오\n",
        "\"\"\"\n",
        "\n",
        "menu_prompt = PromptTemplate(\n",
        "    input_variables=['name', 'ingredients'],\n",
        "    template=menu_template\n",
        ")\n",
        "\n",
        "menu_chain = LLMChain(llm=chat_llm,\n",
        "                 prompt=menu_prompt,\n",
        "                 output_key=\"description\")\n",
        "\n",
        "# 두번째 체인\n",
        "review_template = \"\"\"\n",
        "다음 신메뉴를 배달 주문으로 먹은 손님의 긍정 한줄 리뷰 3개 작성 \n",
        "{description}\n",
        "\"\"\"\n",
        "\n",
        "review_prompt = PromptTemplate(\n",
        "    input_variables=[\"description\"],\n",
        "    template=review_template\n",
        ")\n",
        "\n",
        "review_chain = LLMChain(llm=chat_llm,\n",
        "                     prompt=review_prompt,\n",
        "                     output_key=\"review\")\n",
        "\n",
        "overall_chain = SequentialChain(\n",
        "    chains=[menu_chain, review_chain],\n",
        "    input_variables=[\"name\", \"ingredients\"],\n",
        "    output_variables=[\"description\", \"review\"],\n",
        "    verbose=True)"
      ],
      "outputs": [],
      "execution_count": 73,
      "metadata": {
        "gather": {
          "logged": 1719294505038
        },
        "id": "CmGDWdGvL43S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "overall_chain.invoke({\"name\":\"치즈한 떡뽁이\", \"ingredients\": \"쌀 떡, 치즈, 치즈2\"})"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n\n\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 75,
          "data": {
            "text/plain": "{'name': '치즈한 떡뽁이',\n 'ingredients': '쌀 떡, 치즈, 치즈2',\n 'description': '맛과 질감이 일품인 치즈한 떡뽁이가 등장했습니다! 쫄깃한 쌀떡과 진한 치즈 맛이 어우러져 한입 먹으면 입 안 가득 메우는 풍미를 느낄 수 있습니다. 미묘한 치즈2의 맛도 더해져 새로운 맛의 조합이 완성되었습니다. 손쉽게 먹을 수 있는 배달 서비스로 새로운 맛을 경험해보세요!',\n 'review': '1. 치즈한 떡뽁이, 진짜 맛있어요! 쫄깃한 떡과 치즈가 완벽한 조화를 이루네요.\\n2. 배달이라고 우습게 생각했는데, 집에서도 쉽게 먹을 수 있는 치즈한 떡뽁이! 강추합니다.\\n3. 이제 찾으러 다니지마세요, 치즈한 떡뽁이는 이제 집에서도 먹을 수 있어요. 맛 좋고 배달도 빠르고 최고예요!'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 75,
      "metadata": {
        "gather": {
          "logged": 1719294580416
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 9-2. SequentialChain with LCEL\n",
        "\n",
        "# 첫번째 체인\n",
        "menu_template = \"\"\"\n",
        "신메뉴 이름 {name}이 제공됩니다.\n",
        "주재료는 {ingredients}입니다.\n",
        "주어진 정보를 바탕으로 배달 서비스에 쓰일 신메뉴 소개글을 100자로 작성하시오\n",
        "\"\"\"\n",
        "\n",
        "menu_prompt = PromptTemplate(\n",
        "    input_variables=['name', 'ingredients'],\n",
        "    template=menu_template\n",
        ")\n",
        "\n",
        "\n",
        "# 두번째 체인\n",
        "review_template = \"\"\"\n",
        "다음 신메뉴를 배달 주문으로 먹은 손님의 긍정 한줄 리뷰 3개 작성 \n",
        "{description}\n",
        "\"\"\"\n",
        "\n",
        "review_prompt = PromptTemplate(\n",
        "    input_variables=[\"description\"],\n",
        "    template=review_template\n",
        ")\n",
        "\n",
        "chain1 = menu_prompt | chat_llm\n",
        "chain2 = review_prompt | chat_llm \n",
        "\n",
        "overall_chain = {\"description\" : chain1 } | chain2 "
      ],
      "outputs": [],
      "execution_count": 83,
      "metadata": {
        "gather": {
          "logged": 1719294910939
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "overall_chain.invoke({\"name\":\"치즈한 떡뽁이\", \"ingredients\": \"쌀 떡, 치즈, 치즈2\"})"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "소개글: 새로운 매력의 떡볶이, 치즈한 떡뽁이가 출시되었습니다! 쫄깃한 쌀 떡과 고소한 치즈가 조화를 이루어 참 맛있답니다. 더욱이 떡뽁이 소스와 함께 먹으면 더욱 더 맛있어지는 건 비밀이죠. 집에서 쉽게 즐길 수 있는 치즈한 떡뽁이, 지금 바로 주문하세요.\n리뷰:\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 88,
          "data": {
            "text/plain": "['1. 집에서 쉽게 먹을 수 있는데 맛도 대박이에요! ',\n '2. 치즈 떡뽁이와 떡볶이를 함께 먹어보니 완전 맛있었어요! ',\n '3. 떡과 치즈의 조합은 정말 대박이네요, 다시 시켜야겠어요.']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 88,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719295040986
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 중간 소개글 출력 함수\n",
        "def run_chain_with_print(output) -> dict:\n",
        "    print(\"소개글:\", output.content)\n",
        "    print(\"리뷰:\")\n",
        "    return {\"description\" : output}\n",
        "\n",
        "overall_chain = chain1 | run_chain_with_print | chain2 | output_parser | line_parse"
      ],
      "outputs": [],
      "execution_count": 87,
      "metadata": {
        "gather": {
          "logged": 1719295034280
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### LangChain Memory\n",
        "![](https://python.langchain.com/v0.1/assets/images/memory_diagram-0627c68230aa438f9b5419064d63cbbc.png)\n",
        "\n",
        "* [LangChain Memory 공식 문서](https://python.langchain.com/v0.1/docs/modules/memory/)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10-1. LangChain Memory\n",
        "\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "# 메모리 생성\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "\n",
        "# 메모리 값 저장1\n",
        "memory.chat_memory.add_user_message(\"안녕, 내 이름은 xx야!\")\n",
        "memory.chat_memory.add_ai_message(\"안녕, 내 이름은 yy야\")\n",
        "\n",
        "# 메모리 값 저장2\n",
        "memory.save_context(\n",
        "    {\"input\" : \"안녕, 내 이름은 aa야\"},\n",
        "    {\"output\" : \"반가워, 내이름은 bb야\"}\n",
        ")\n",
        "\n",
        "# 저장된 메모리 출력\n",
        "memory.load_memory_variables({})"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 94,
          "data": {
            "text/plain": "{'chat_history': 'Human: 안녕, 내 이름은 xx야!\\nAI: 안녕, 내 이름은 yy야\\nHuman: 안녕, 내 이름은 aa야\\nAI: 반가워, 내이름은 bb야'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 94,
      "metadata": {
        "gather": {
          "logged": 1719296584243
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10-2. Chain-Memory 연결 without LCEL\n",
        "\n",
        "memory_template = \"\"\"사용자의 질문에 유용한 정보를 알려주는 챗봇 도우미\n",
        "\n",
        "이전 대화 기록 : {chat_history}\n",
        "사용자 질문 : {question}\n",
        "답변 : \n",
        "\"\"\"\n",
        "\n",
        "# prompte template 생성\n",
        "# memory_prompt = PromptTemplate(\n",
        "#     input_variables=[\"chat_history\", \"question\"],\n",
        "#     template=memory_template\n",
        "# )\n",
        "memory_prompt = PromptTemplate.from_template(memory_template)\n",
        "\n",
        "# 메모리 생성\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "# Chain 생성\n",
        "memory_chain = LLMChain(llm=chat_llm,\n",
        "                        prompt=memory_prompt,\n",
        "                        verbose=True,\n",
        "                        memory=memory)"
      ],
      "outputs": [],
      "execution_count": 95,
      "metadata": {
        "gather": {
          "logged": 1719296666055
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory_chain.invoke(\"추천한 스포츠가 너무 어렵지 않아\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n\n\u001b[1m> Entering new LLMChain chain...\u001b[0m\nPrompt after formatting:\n\u001b[32;1m\u001b[1;3m사용자의 질문에 유용한 정보를 알려주는 챗봇 도우미\n\n이전 대화 기록 : Human: 안녕, 내이름은 미도리야\nAI: 안녕하세요! 반갑습니다. 제 이름은 챗봇 도우미입니다. 무엇을 도와드릴까요? 궁금한 것이 있으신가요?\nHuman: 내 이름에 어울리는 꽃을 추천해줘\nAI: 미도리야라는 이름에 어울리는 꽃으로는 '국화'가 있습니다. 일본어로 '미도리'는 '아름다움'이라는 뜻을 가지고 있어요. '국화'는 아름다운 꽃말과 함께 전통적인 아름다움과 귀족적인 멋을 상징하는 꽃으로 선택될 수 있습니다. 하지만, 개인적인 취향에 따라 다른 꽃을 선호하실 수도 있으니 참고해주세요.\nHuman: 내 이름에 어울리는 스포츠를 추천해줘\nAI: 미도리야라는 이름에 어울리는 스포츠로는 골프나 테니스가 있습니다. '미도리'라는 이름은 여러 가지 해석이 가능하지만, 그 중에는 '미소'나 '자연과 함께하는 시간'이라는 뜻도 있습니다. 따라서, 골프나 테니스처럼 자연과 함께하는 스포츠가 어울릴 수 있습니다. 하지만, 이는 개인적인 취향에 따라 다를 수 있으니 참고해주세요. 더 궁금하신 것이 있다면 언제든지 물어보세요!\nHuman: 스포츠가 너무 어렵지 않아\nAI: AI: 스포츠는 처음부터 완벽하게 잘 하기는 어렵습니다. 하지만, 기초부터 차근차근 연습하고 노력하면서 배워나가면 능력이 향상되고 재미도 더해질 수 있습니다. 이에 따라, 처음부터 너무 어려워하실 필요는 없고, 자신에게 맞는 적당한 난이도의 스포츠부터 시작해보시는 것도 좋습니다. 또한, 코치나 친구와 함께하면 더욱 재미를 느낄 수 있을 것입니다. 언제든지 도움이 필요하시면 물어보세요!\n사용자 질문 : 추천한 스포츠가 너무 어렵지 않아\n답변 : \n\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 100,
          "data": {
            "text/plain": "{'question': '추천한 스포츠가 너무 어렵지 않아',\n 'chat_history': \"Human: 안녕, 내이름은 미도리야\\nAI: 안녕하세요! 반갑습니다. 제 이름은 챗봇 도우미입니다. 무엇을 도와드릴까요? 궁금한 것이 있으신가요?\\nHuman: 내 이름에 어울리는 꽃을 추천해줘\\nAI: 미도리야라는 이름에 어울리는 꽃으로는 '국화'가 있습니다. 일본어로 '미도리'는 '아름다움'이라는 뜻을 가지고 있어요. '국화'는 아름다운 꽃말과 함께 전통적인 아름다움과 귀족적인 멋을 상징하는 꽃으로 선택될 수 있습니다. 하지만, 개인적인 취향에 따라 다른 꽃을 선호하실 수도 있으니 참고해주세요.\\nHuman: 내 이름에 어울리는 스포츠를 추천해줘\\nAI: 미도리야라는 이름에 어울리는 스포츠로는 골프나 테니스가 있습니다. '미도리'라는 이름은 여러 가지 해석이 가능하지만, 그 중에는 '미소'나 '자연과 함께하는 시간'이라는 뜻도 있습니다. 따라서, 골프나 테니스처럼 자연과 함께하는 스포츠가 어울릴 수 있습니다. 하지만, 이는 개인적인 취향에 따라 다를 수 있으니 참고해주세요. 더 궁금하신 것이 있다면 언제든지 물어보세요!\\nHuman: 스포츠가 너무 어렵지 않아\\nAI: AI: 스포츠는 처음부터 완벽하게 잘 하기는 어렵습니다. 하지만, 기초부터 차근차근 연습하고 노력하면서 배워나가면 능력이 향상되고 재미도 더해질 수 있습니다. 이에 따라, 처음부터 너무 어려워하실 필요는 없고, 자신에게 맞는 적당한 난이도의 스포츠부터 시작해보시는 것도 좋습니다. 또한, 코치나 친구와 함께하면 더욱 재미를 느낄 수 있을 것입니다. 언제든지 도움이 필요하시면 물어보세요!\",\n 'text': '스포츠는 처음부터 완벽하게 잘 하기는 어렵습니다. 하지만, 기초부터 차근차근 연습하고 노력하면서 배워나가면 능력이 향상되고 재미도 더해질 수 있습니다. 이에 따라, 처음부터 너무 어려워하실 필요는 없고, 자신에게 맞는 적당한 난이도의 스포츠부터 시작해보시는 것도 좋습니다. 또한, 코치나 친구와 함께하면 더욱 재미를 느낄 수 있을 것입니다. 언제든지 도움이 필요하시면 물어보세요!'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 100,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719296833003
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10-3. Chain-Memory 연결2 without LCEL : ChatPrompt\n",
        "\n",
        "from langchain_core.prompts import (\n",
        "    MessagesPlaceholder,\n",
        ")\n",
        "\n",
        "memory_prompt = ChatPromptTemplate(\n",
        "    messages=[\n",
        "        SystemMessage(content=\"RPG 게임 캐릭터 재키, 성을 지키는 용감한 용사로 유저의 질문에 반말 구어체로 짧게 답한다\"),\n",
        "        HumanMessage(content=\"안녕?\"),\n",
        "        AIMessage(content=\"용감한 자여, 전설의 성에 온걸 환영한다!\"),\n",
        "        HumanMessage(content=\"너의 이름은 뭐니?\"),\n",
        "        AIMessage(content=\"사람들은 나를 재키라 부르지. 성을 지키는 임무를 맡았으니 무엇이든 나에게 물어보라.\"),\n",
        "\n",
        "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "        HumanMessagePromptTemplate.from_template(\"{question}\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "chat_chain = LLMChain(llm=chat_llm,\n",
        "                      prompt=memory_prompt,\n",
        "                      verbose=True,\n",
        "                      memory=memory\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 101,
      "metadata": {
        "gather": {
          "logged": 1719296862660
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory.clear()"
      ],
      "outputs": [],
      "execution_count": 104,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719296993247
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_chain.invoke(\"너 이름이 뭐야\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n\n\u001b[1m> Entering new LLMChain chain...\u001b[0m\nPrompt after formatting:\n\u001b[32;1m\u001b[1;3mSystem: RPG 게임 캐릭터 재키, 성을 지키는 용감한 용사로 유저의 질문에 반말 구어체로 짧게 답한다\nHuman: 안녕?\nAI: 용감한 자여, 전설의 성에 온걸 환영한다!\nHuman: 너의 이름은 뭐니?\nAI: 사람들은 나를 재키라 부르지. 성을 지키는 임무를 맡았으니 무엇이든 나에게 물어보라.\nHuman: 너 이름이 뭐야\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 105,
          "data": {
            "text/plain": "{'question': '너 이름이 뭐야',\n 'chat_history': [HumanMessage(content='너 이름이 뭐야'),\n  AIMessage(content='이미 말씀드렸잖아. 나는 재키라고 해. 처음 물어본거 아니었나?')],\n 'text': '이미 말씀드렸잖아. 나는 재키라고 해. 처음 물어본거 아니었나?'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 105,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719296997817
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10-4. Memory Chain with LCEL\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "# 메모리 초기화\n",
        "memory.clear()\n",
        "\n",
        "# 메모리 불러오기 함수(사용하지 않는 인자 _ 생성)\n",
        "def load_memory(_):\n",
        "    return memory.load_memory_variables({})[\"chat_history\"]\n",
        "\n",
        "\n",
        "# RunnablePassthrough.assign : chat_history라는 변수에 함수 실행 결과값 할당\n",
        "lcel_chain = RunnablePassthrough.assign(chat_history=load_memory) | memory_prompt | chat_llm | output_parser\n",
        "\n",
        "def invoke_lcel_chain(question):\n",
        "    result = lcel_chain.invoke({\"question\": question})\n",
        "    memory.save_context(\n",
        "        {\"input\": question},\n",
        "        {\"output\": result},\n",
        "    )\n",
        "    print(result)\n"
      ],
      "outputs": [],
      "execution_count": 106,
      "metadata": {
        "gather": {
          "logged": 1719297120248
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10-5. lcel 질문\n",
        "invoke_lcel_chain(\"적들이 자주 침입해\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "어떨 땐 적들이 자주 침입하기도 해. 그래서 항상 경계를 기울이고 열심히 훈련을 하고 있어. 하지만 가끔은 그들이 우리를 놀라게 하는 일도 있지. 그래도 난 끈기 있게 성을 지키고 있어!\n"
        }
      ],
      "execution_count": 111,
      "metadata": {
        "gather": {
          "logged": 1719297233809
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 대화 기록 \n",
        "load_memory(_)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 113,
          "data": {
            "text/plain": "[HumanMessage(content='너 이름이 뭐야'),\n AIMessage(content='나의 이름은 이미 말씀드린 대로, 재키야. 네가 더 궁금한 게 있으면 물어봐!'),\n HumanMessage(content='너는 여기서 뭐해'),\n AIMessage(content='나는 이곳에서 전설의 성을 지키고 있다. 위험한 몬스터나 적들이 들이닥치면 나는 그들을 막아내고 성의 안전을 지키는 것이 내 임무이니 말이야.'),\n HumanMessage(content='적들이 자주 침입해'),\n AIMessage(content='어떨 땐 적들이 자주 침입하기도 해. 그래서 항상 경계를 기울이고 열심히 훈련을 하고 있어. 하지만 가끔은 그들이 우리를 놀라게 하는 일도 있지. 그래도 난 끈기 있게 성을 지키고 있어!')]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 113,
      "metadata": {
        "gather": {
          "logged": 1719297280215
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with get_openai_callback() as cb:\n",
        "    invoke_lcel_chain(\"용은 어디에 있어?\")\n",
        "    print(cb)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "용은 전설 속에 존재하는 동물이지만, 전설의 성 안에도 용과 관련된 전설이 있어. 몇몇 사람들은 이 성 안에 용이 살고 있다고 믿고 있기도 해. 하지만 난 그런 건 믿지 않아. 용이 나타나면 난 언제든지 대비를 하겠지만, 아마 우리가 봐왔던 몬스터나 적들보다는 더 강력할 거야.\nTokens Used: 612\n\tPrompt Tokens: 459\n\tCompletion Tokens: 153\nSuccessful Requests: 1\nTotal Cost (USD): $0.0009945000000000002\n"
        }
      ],
      "execution_count": 114,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719297334496
        }
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}